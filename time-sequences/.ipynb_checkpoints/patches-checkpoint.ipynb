{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f27d5b-dd15-45b0-aaf0-31483d7a5f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow_dataset.py\n",
    "import ast\n",
    "import rasterio\n",
    "import rasterio.windows\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "PATCH_SIZE = 33\n",
    "SEQ_LEN = 6\n",
    "HORIZONS = 3\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "DEM_PATH = r\"C:\\Users\\Ankit\\Datasets_Forest_fire\\merged_DEM_30m_32644_aligned_filled.tif\"\n",
    "LULC_PATH = r\"C:\\Users\\Ankit\\Datasets_Forest_fire\\lulc_maps_tif\\LULC_2015_clipped_30m_filled_categorical.tif\"\n",
    "\n",
    "CSV_INDEX = r\"C:\\Users\\Ankit\\Datasets_Forest_fire\\sequence_index_hourly.csv\"\n",
    "\n",
    "# -----------------------------\n",
    "# Load static rasters (DEM, LULC) into memory\n",
    "# -----------------------------\n",
    "with rasterio.open(DEM_PATH) as src:\n",
    "    DEM = src.read(1)  # 2D numpy array (H, W)\n",
    "with rasterio.open(LULC_PATH) as src:\n",
    "    LULC = src.read(1)  # 2D numpy array (H, W)\n",
    "\n",
    "# Basic checks\n",
    "assert DEM.shape == LULC.shape, \"DEM and LULC must have same shape/alignment.\"\n",
    "\n",
    "H_RASTER, W_RASTER = DEM.shape\n",
    "HALF = PATCH_SIZE // 2\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: parse index strings like \"[1, 2, 3]\" to list[int]\n",
    "# -----------------------------\n",
    "def parse_list_column(s):\n",
    "    # handle both already-list objects and string representations\n",
    "    if isinstance(s, list):\n",
    "        return s\n",
    "    try:\n",
    "        return list(map(int, ast.literal_eval(s)))\n",
    "    except Exception:\n",
    "        # fallback: split by comma\n",
    "        s2 = s.strip(\"[] \")\n",
    "        if s2 == \"\":\n",
    "            return []\n",
    "        return [int(x) for x in s2.split(\",\")]\n",
    "\n",
    "# -----------------------------\n",
    "# Core: single-sample extractor (returns numpy arrays)\n",
    "# -----------------------------\n",
    "def extract_sample(row, patch_size=PATCH_SIZE):\n",
    "    \"\"\"\n",
    "    row: a pandas Series (one CSV row)\n",
    "    returns: X -> np.float32 (SEQ_LEN, H, W, C)\n",
    "             y -> np.float32 (HORIZONS, H, W)\n",
    "    Assumes CSV columns:\n",
    "      seq_band_idxs, target_band_idxs,\n",
    "      era5_t2m_file, era5_d2m_file, era5_tp_file, era5_u10_file, era5_v10_file,\n",
    "      viirs_file, row, col\n",
    "    \"\"\"\n",
    "    r = int(row[\"row\"])\n",
    "    c = int(row[\"col\"])\n",
    "    half = patch_size // 2\n",
    "\n",
    "    # boundary check\n",
    "    if r - half < 0 or r + half >= H_RASTER or c - half < 0 or c + half >= W_RASTER:\n",
    "        raise IndexError(f\"Center {(r,c)} too close to edge for patch size {patch_size}\")\n",
    "\n",
    "    # parse indices\n",
    "    seq_idxs = parse_list_column(row[\"seq_band_idxs\"])\n",
    "    target_idxs = parse_list_column(row[\"target_band_idxs\"])\n",
    "\n",
    "    # ERA5 variable filepaths\n",
    "    era5_paths = [\n",
    "        row[\"era5_t2m_file\"],\n",
    "        row[\"era5_d2m_file\"],\n",
    "        row[\"era5_tp_file\"],\n",
    "        row[\"era5_u10_file\"],\n",
    "        row[\"era5_v10_file\"],\n",
    "    ]\n",
    "    # We'll build ERA5 patches with channel ordering: [timestep, H, W, var_channels]\n",
    "    era5_seq = []  # will become (SEQ_LEN, H, W, 5)\n",
    "\n",
    "    for band_idx in seq_idxs:\n",
    "        # read the same (row,col) window from every ERA5 var and stack channels\n",
    "        var_chs = []\n",
    "        for var_path in era5_paths:\n",
    "            with rasterio.open(var_path) as src:\n",
    "                win = rasterio.windows.Window(c-half, r-half, patch_size, patch_size)\n",
    "                # rasterio band indexing is 1-based; band_idx should be int\n",
    "                patch = src.read(band_idx, window=win)  # shape (H, W)\n",
    "                var_chs.append(patch)\n",
    "        # stack variables -> shape (H, W, 5)\n",
    "        timestep_patch = np.stack(var_chs, axis=-1)\n",
    "        era5_seq.append(timestep_patch.astype(np.float32))\n",
    "\n",
    "    era5_seq = np.stack(era5_seq, axis=0)  # (SEQ_LEN, H, W, 5)\n",
    "\n",
    "    # Static patches (DEM + LULC)\n",
    "    dem_patch = DEM[r-half:r+half+1, c-half:c+half+1].astype(np.float32)\n",
    "    lulc_patch = LULC[r-half:r+half+1, c-half:c+half+1].astype(np.float32)\n",
    "\n",
    "    # repeat across time\n",
    "    dem_seq = np.repeat(dem_patch[None, :, :], len(seq_idxs), axis=0)  # (SEQ_LEN, H, W)\n",
    "    lulc_seq = np.repeat(lulc_patch[None, :, :], len(seq_idxs), axis=0)  # (SEQ_LEN, H, W)\n",
    "\n",
    "    # concatenate static channels to ERA5 per-timestep channels\n",
    "    # era5_seq shape: (SEQ_LEN, H, W, 5)\n",
    "    dem_seq = dem_seq[..., None]   # (SEQ_LEN, H, W, 1)\n",
    "    lulc_seq = lulc_seq[..., None] # (SEQ_LEN, H, W, 1)\n",
    "    X = np.concatenate([era5_seq, dem_seq, lulc_seq], axis=-1)  # (SEQ_LEN, H, W, 7)\n",
    "\n",
    "    # Targets: read VIIRS bands for horizons (patches)\n",
    "    y_list = []\n",
    "    with rasterio.open(row[\"viirs_file\"]) as src:\n",
    "        for b in target_idxs:\n",
    "            win = rasterio.windows.Window(c-half, r-half, patch_size, patch_size)\n",
    "            patch = src.read(b, window=win)  # (H, W)\n",
    "            y_list.append(patch.astype(np.float32))\n",
    "    y = np.stack(y_list, axis=0)  # (HORIZONS, H, W)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# -----------------------------\n",
    "# Generator for tf.data\n",
    "# -----------------------------\n",
    "def generator_from_df(df):\n",
    "    \"\"\"\n",
    "    Yields X, y numpy arrays for each row in df.\n",
    "    If you want random sampling of centers per row, modify this function.\n",
    "    \"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            X, y = extract_sample(row)\n",
    "            # Optionally: normalization steps here (mean/std)\n",
    "            yield X, y\n",
    "        except Exception as e:\n",
    "            # print and skip invalid rows (e.g., patch near edge)\n",
    "            print(\"skipping row due to:\", e)\n",
    "            continue\n",
    "\n",
    "# -----------------------------\n",
    "# Build tf.data.Dataset\n",
    "# -----------------------------\n",
    "df_index = pd.read_csv(CSV_INDEX)\n",
    "\n",
    "# Ensure columns names match: if your CSV uses different column names adapt here.\n",
    "required = [\"seq_band_idxs\", \"target_band_idxs\",\n",
    "            \"era5_t2m_file\", \"era5_d2m_file\", \"era5_tp_file\",\n",
    "            \"era5_u10_file\", \"era5_v10_file\",\n",
    "            \"viirs_file\", \"row\", \"col\"]\n",
    "missing = [c for c in required if c not in df_index.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"CSV is missing required columns: {missing}\")\n",
    "\n",
    "# create the tf.data.Dataset\n",
    "output_signature = (\n",
    "    tf.TensorSpec(shape=(None, PATCH_SIZE, PATCH_SIZE, 7), dtype=tf.float32),  # X: (SEQ_LEN, H, W, C) -> None for SEQ_LEN if variable\n",
    "    tf.TensorSpec(shape=(None, PATCH_SIZE, PATCH_SIZE), dtype=tf.float32)       # y: (HORIZONS, H, W)\n",
    ")\n",
    "\n",
    "# If SEQ_LEN and HORIZONS are fixed we can put concrete shapes:\n",
    "output_signature = (\n",
    "    tf.TensorSpec(shape=(SEQ_LEN, PATCH_SIZE, PATCH_SIZE, 7), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(HORIZONS, PATCH_SIZE, PATCH_SIZE), dtype=tf.float32),\n",
    ")\n",
    "\n",
    "ds = tf.data.Dataset.from_generator(\n",
    "    lambda: generator_from_df(df_index),\n",
    "    output_signature=output_signature\n",
    ")\n",
    "\n",
    "ds = ds.shuffle(1024).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# -----------------------------\n",
    "# Quick test: iterate once\n",
    "# -----------------------------\n",
    "for X_batch, y_batch in ds.take(1):\n",
    "    print(\"X batch shape:\", X_batch.shape)  # (B, SEQ_LEN, H, W, C)\n",
    "    print(\"y batch shape:\", y_batch.shape)  # (B, HORIZONS, H, W)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
