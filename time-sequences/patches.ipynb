{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6f27d5b-dd15-45b0-aaf0-31483d7a5f33",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "CSV must contain coordinate columns. Tried [['row', 'col'], ['x', 'y'], ['lat', 'lon'], ['center_row', 'center_col'], ['patch_row', 'patch_col']]. Found ['center_time', 'seq_band_idxs', 'target_band_idxs', 'era5_t2m_file', 'era5_d2m_file', 'era5_tp_file', 'era5_u10_file', 'era5_v10_file', 'viirs_file', 'dem_file', 'lulc_file']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 139\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCSV must contain coordinate columns. Tried \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoord_options\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(df_index\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m     )\n\u001b[0;32m    143\u001b[0m required \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_band_idxs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_band_idxs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    144\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mera5_t2m_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mera5_d2m_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mera5_tp_file\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mera5_u10_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mera5_v10_file\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    146\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mviirs_file\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    147\u001b[0m missing \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m required \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df_index\u001b[38;5;241m.\u001b[39mcolumns]\n",
      "\u001b[1;31mValueError\u001b[0m: CSV must contain coordinate columns. Tried [['row', 'col'], ['x', 'y'], ['lat', 'lon'], ['center_row', 'center_col'], ['patch_row', 'patch_col']]. Found ['center_time', 'seq_band_idxs', 'target_band_idxs', 'era5_t2m_file', 'era5_d2m_file', 'era5_tp_file', 'era5_u10_file', 'era5_v10_file', 'viirs_file', 'dem_file', 'lulc_file']"
     ]
    }
   ],
   "source": [
    "# tensorflow_dataset_dual_lulc.py\n",
    "import ast\n",
    "import rasterio\n",
    "import rasterio.windows\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "PATCH_SIZE = 33\n",
    "SEQ_LEN = 6\n",
    "HORIZONS = 3\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "DEM_PATH   = r\"C:\\Users\\Ankit\\Datasets_Forest_fire\\merged_DEM_30m_32644_aligned_filled.tif\"\n",
    "LULC_2015_PATH = r\"C:\\Users\\Ankit\\Datasets_Forest_fire\\lulc_maps_tif\\LULC_2015_clipped_30m_filled_categorical.tif\"\n",
    "LULC_2016_PATH = r\"C:\\Users\\Ankit\\Datasets_Forest_fire\\lulc_maps_tif\\LULC_2016_clipped_30m_filled_categorical.tif\"\n",
    "\n",
    "CSV_INDEX = r\"C:\\Users\\Ankit\\Datasets_Forest_fire\\sequence_index_hourly.csv\"\n",
    "\n",
    "# -----------------------------\n",
    "# Load static rasters (DEM, LULC) into memory\n",
    "# -----------------------------\n",
    "with rasterio.open(DEM_PATH) as src:\n",
    "    DEM = src.read(1)\n",
    "    DEM_TRANSFORM = src.transform\n",
    "with rasterio.open(LULC_2015_PATH) as src:\n",
    "    LULC_2015 = src.read(1)\n",
    "with rasterio.open(LULC_2016_PATH) as src:\n",
    "    LULC_2016 = src.read(1)\n",
    "\n",
    "assert DEM.shape == LULC_2015.shape == LULC_2016.shape, \"DEM and LULC maps must align.\"\n",
    "\n",
    "H_RASTER, W_RASTER = DEM.shape\n",
    "HALF = PATCH_SIZE // 2\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def parse_list_column(s):\n",
    "    if isinstance(s, list):\n",
    "        return s\n",
    "    try:\n",
    "        return list(map(int, ast.literal_eval(s)))\n",
    "    except Exception:\n",
    "        s2 = s.strip(\"[] \")\n",
    "        if s2 == \"\":\n",
    "            return []\n",
    "        return [int(x) for x in s2.split(\",\")]\n",
    "\n",
    "# -----------------------------\n",
    "# Core extraction\n",
    "# -----------------------------\n",
    "def extract_sample(row, coord_cols, patch_size=PATCH_SIZE):\n",
    "    # --- coordinates ---\n",
    "    if coord_cols[0] in [\"lat\", \"lon\"]:\n",
    "        lon = float(row[\"lon\"])\n",
    "        lat = float(row[\"lat\"])\n",
    "        c, r = ~DEM_TRANSFORM * (lon, lat)\n",
    "        r, c = int(r), int(c)\n",
    "    else:\n",
    "        r = int(row[coord_cols[0]])\n",
    "        c = int(row[coord_cols[1]])\n",
    "\n",
    "    half = patch_size // 2\n",
    "    if r - half < 0 or r + half >= H_RASTER or c - half < 0 or c + half >= W_RASTER:\n",
    "        raise IndexError(f\"Center {(r,c)} too close to edge for patch size {patch_size}\")\n",
    "\n",
    "    # --- parse indices ---\n",
    "    seq_idxs = parse_list_column(row[\"seq_band_idxs\"])\n",
    "    target_idxs = parse_list_column(row[\"target_band_idxs\"])\n",
    "\n",
    "    # --- ERA5 variable filepaths ---\n",
    "    era5_paths = [\n",
    "        row[\"era5_t2m_file\"],\n",
    "        row[\"era5_d2m_file\"],\n",
    "        row[\"era5_tp_file\"],\n",
    "        row[\"era5_u10_file\"],\n",
    "        row[\"era5_v10_file\"],\n",
    "    ]\n",
    "    era5_seq = []\n",
    "    for band_idx in seq_idxs:\n",
    "        var_chs = []\n",
    "        for var_path in era5_paths:\n",
    "            with rasterio.open(var_path) as src:\n",
    "                win = rasterio.windows.Window(c-half, r-half, patch_size, patch_size)\n",
    "                patch = src.read(band_idx, window=win)\n",
    "                var_chs.append(patch)\n",
    "        timestep_patch = np.stack(var_chs, axis=-1)\n",
    "        era5_seq.append(timestep_patch.astype(np.float32))\n",
    "    era5_seq = np.stack(era5_seq, axis=0)  # (SEQ_LEN, H, W, 5)\n",
    "\n",
    "    # --- static patches ---\n",
    "    dem_patch   = DEM[r-half:r+half+1, c-half:c+half+1].astype(np.float32)\n",
    "    lulc2015_patch = LULC_2015[r-half:r+half+1, c-half:c+half+1].astype(np.float32)\n",
    "    lulc2016_patch = LULC_2016[r-half:r+half+1, c-half:c+half+1].astype(np.float32)\n",
    "\n",
    "    dem_seq   = np.repeat(dem_patch[None, :, :], len(seq_idxs), axis=0)\n",
    "    lulc2015_seq = np.repeat(lulc2015_patch[None, :, :], len(seq_idxs), axis=0)\n",
    "    lulc2016_seq = np.repeat(lulc2016_patch[None, :, :], len(seq_idxs), axis=0)\n",
    "\n",
    "    dem_seq   = dem_seq[..., None]\n",
    "    lulc2015_seq = lulc2015_seq[..., None]\n",
    "    lulc2016_seq = lulc2016_seq[..., None]\n",
    "\n",
    "    X = np.concatenate([era5_seq, dem_seq, lulc2015_seq, lulc2016_seq], axis=-1)  # (SEQ_LEN,H,W,8)\n",
    "\n",
    "    # --- target VIIRS ---\n",
    "    y_list = []\n",
    "    with rasterio.open(row[\"viirs_file\"]) as src:\n",
    "        for b in target_idxs:\n",
    "            win = rasterio.windows.Window(c-half, r-half, patch_size, patch_size)\n",
    "            patch = src.read(b, window=win)\n",
    "            y_list.append(patch.astype(np.float32))\n",
    "    y = np.stack(y_list, axis=0)  # (HORIZONS,H,W)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# -----------------------------\n",
    "# Build tf.data.Dataset\n",
    "# -----------------------------\n",
    "df_index = pd.read_csv(CSV_INDEX)\n",
    "\n",
    "# Detect coordinate columns\n",
    "coord_options = [\n",
    "    [\"row\", \"col\"],\n",
    "    [\"x\", \"y\"],\n",
    "    [\"lat\", \"lon\"],\n",
    "    [\"center_row\", \"center_col\"],\n",
    "    [\"patch_row\", \"patch_col\"],\n",
    "]\n",
    "for alt in coord_options:\n",
    "    if all(c in df_index.columns for c in alt):\n",
    "        coord_cols = alt\n",
    "        break\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"CSV must contain coordinate columns. Tried {coord_options}. Found {list(df_index.columns)}\"\n",
    "    )\n",
    "\n",
    "required = [\"seq_band_idxs\", \"target_band_idxs\",\n",
    "            \"era5_t2m_file\", \"era5_d2m_file\", \"era5_tp_file\",\n",
    "            \"era5_u10_file\", \"era5_v10_file\",\n",
    "            \"viirs_file\"]\n",
    "missing = [c for c in required if c not in df_index.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"CSV is missing required columns: {missing}\")\n",
    "\n",
    "def generator_from_df(df):\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            X, y = extract_sample(row, coord_cols)\n",
    "            yield X, y\n",
    "        except Exception as e:\n",
    "            print(\"Skipping row:\", e)\n",
    "            continue\n",
    "\n",
    "# Output signature with 8 channels\n",
    "output_signature = (\n",
    "    tf.TensorSpec(shape=(SEQ_LEN, PATCH_SIZE, PATCH_SIZE, 8), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(HORIZONS, PATCH_SIZE, PATCH_SIZE), dtype=tf.float32),\n",
    ")\n",
    "\n",
    "ds = tf.data.Dataset.from_generator(\n",
    "    lambda: generator_from_df(df_index),\n",
    "    output_signature=output_signature\n",
    ")\n",
    "\n",
    "ds = ds.shuffle(1024).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# -----------------------------\n",
    "# Quick test\n",
    "# -----------------------------\n",
    "for X_batch, y_batch in ds.take(1):\n",
    "    print(\"X batch shape:\", X_batch.shape)  # (B,SEQ_LEN,H,W,8)\n",
    "    print(\"y batch shape:\", y_batch.shape)  # (B,HORIZONS,H,W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d743efd6-b9f6-4276-a53a-9bf6786faaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
