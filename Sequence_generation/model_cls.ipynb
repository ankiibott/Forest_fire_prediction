{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "058e0175-ef36-46b5-b2b1-1d35d258311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "SEQ_LEN = 6                 \n",
    "HORIZONS = 3               \n",
    "PATCH_SIZE = 13             \n",
    "HALF = PATCH_SIZE // 2\n",
    "FILL_NAN_VALUE = 0.0\n",
    "\n",
    "REQUIRED_COLS = [\n",
    "    \"era5_t2m_file\", \"era5_d2m_file\", \"era5_tp_file\",\n",
    "    \"era5_u10_file\", \"era5_v10_file\",\n",
    "    \"viirs_file\", \"dem_file\", \"lulc_file\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed507d4-d0c0-4c23-b3f4-e12115f05a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f5774f7-5a3f-4c9b-b70b-bfdfafab3ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae142a5-292c-4193-9e60-d501771b46db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_single_raster(path):\n",
    "    with rasterio.open(path) as src:\n",
    "        arr = src.read() \n",
    "\n",
    "    if arr.shape[0] == 1:\n",
    "        \n",
    "        return arr[0]\n",
    "    else:\n",
    "     \n",
    "        return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38d95c89-2d72-4f83-897d-966405060ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rasters(df, raster_cols, max_workers=8):\n",
    "    \n",
    "    all_paths = set()\n",
    "\n",
    "    for col in raster_cols:\n",
    "        if col in df.columns:\n",
    "            all_paths.update(df[col].dropna().unique())\n",
    "    all_paths = list(all_paths)\n",
    "\n",
    "    cache = {}\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        results = list(ex.map(_load_single_raster, all_paths))\n",
    "\n",
    "    for path, arr in zip(all_paths, results):\n",
    "        if arr is not None:\n",
    "            cache[path] = arr\n",
    "    return cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edee5feb-0f88-4090-ab3f-4c28838c8f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_center(h, w, patch_size=PATCH_SIZE):\n",
    "    half = patch_size // 2\n",
    "    r = np.clip(h // 2, half, h - half - 1)\n",
    "    c = np.clip(w // 2, half, w - half - 1)\n",
    "    return r, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fce6a62-85f9-4b91-a739-a40022b4718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_patch(arr, row, col, patch_size=PATCH_SIZE):\n",
    "    half = patch_size // 2\n",
    "    h, w = arr.shape\n",
    "\n",
    "    r0 = row - half\n",
    "    r1 = row + half + 1\n",
    "    c0 = col - half\n",
    "    c1 = col + half + 1\n",
    "\n",
    "    patch = np.zeros((patch_size, patch_size), dtype=arr.dtype)\n",
    "\n",
    "    r0_clip = max(r0, 0)\n",
    "    r1_clip = min(r1, h)\n",
    "    c0_clip = max(c0, 0)\n",
    "    c1_clip = min(c1, w)\n",
    "\n",
    "    pr0 = r0_clip - r0\n",
    "    pr1 = pr0 + (r1_clip - r0_clip)\n",
    "    pc0 = c0_clip - c0\n",
    "    pc1 = pc0 + (c1_clip - c0_clip)\n",
    "\n",
    "    patch[pr0:pr1, pc0:pc1] = arr[r0_clip:r1_clip, c0_clip:c1_clip]\n",
    "\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e402e30a-b656-4fe1-9eb9-99fc3e3171a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sample(seq_rows, horizon_rows, cache, force_fire=False):\n",
    "    seq_patches = []\n",
    "\n",
    "   \n",
    "    for _, row in seq_rows.iterrows():\n",
    "        bands = []\n",
    "        for var in [\"era5_t2m_file\", \"era5_d2m_file\", \"era5_tp_file\",\n",
    "                    \"era5_u10_file\", \"era5_v10_file\"]:\n",
    "            arr = cache[row[var]]\n",
    "\n",
    "            if len(arr.shape) == 3:\n",
    "                arr = arr[0]\n",
    "\n",
    "            h, w = arr.shape\n",
    "            r, c = _safe_center(h, w)\n",
    "            bands.append(_extract_patch(arr, r, c))\n",
    "\n",
    "        dem = cache[row[\"dem_file\"]]\n",
    "        lulc = cache[row[\"lulc_file\"]]\n",
    "\n",
    "        if len(dem.shape) == 3:\n",
    "            dem = dem[0]\n",
    "        if len(lulc.shape) == 3:\n",
    "            lulc = lulc[0]\n",
    "\n",
    "        h, w = dem.shape\n",
    "        r, c = _safe_center(h, w)\n",
    "        bands.append(_extract_patch(dem, r, c))\n",
    "        bands.append(_extract_patch(lulc, r, c))\n",
    "\n",
    "        seq_patches.append(np.stack(bands, axis=-1))\n",
    "\n",
    "    X = np.stack(seq_patches, axis=0)\n",
    "\n",
    "\n",
    "    horizon_patches = []\n",
    "   \n",
    "    for _, row in horizon_rows.iterrows():\n",
    "        viirs_stack = cache[row[\"viirs_file\"]]\n",
    "        \n",
    "    \n",
    "        target_band_idx_list = eval(row[\"target_band_idxs\"])\n",
    " \n",
    "        idx = target_band_idx_list[0]\n",
    "        \n",
    "        band = viirs_stack[idx - 1]\n",
    "        h, w = band.shape\n",
    "        r, c = _safe_center(h, w)\n",
    "\n",
    "        if force_fire and np.any(band > 0):\n",
    "            fire_pos = np.argwhere(band > 0)\n",
    "            r, c = fire_pos[np.random.randint(len(fire_pos))]\n",
    "\n",
    "        horizon_patches.append(_extract_patch(band, r, c))\n",
    "\n",
    "    y = np.stack(horizon_patches, axis=0)\n",
    "\n",
    "    return X.astype(\"float32\"), y.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed58a017-a51e-4db8-aa39-6fcd8b5befb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "\n",
    "# def make_generator(df, cache, fire_ratio=0.5):\n",
    "    \n",
    "#     valid_start_indices = list(range(len(df) - SEQ_LEN - HORIZONS + 1))\n",
    "\n",
    "#     fire_start_indices = []\n",
    "#     non_fire_start_indices = []\n",
    "    \n",
    "#     for i in valid_start_indices:\n",
    "#         horizon_rows = df.iloc[i + SEQ_LEN : i + SEQ_LEN + HORIZONS]\n",
    "#         # This line iterates through DataFrame rows to check for fire, which is fine.\n",
    "#         has_fire = any(np.any(cache[row[\"viirs_file\"]] > 0) for _, row in horizon_rows.iterrows())\n",
    "        \n",
    "#         if has_fire:\n",
    "#             fire_start_indices.append(i)\n",
    "#         else:\n",
    "#             non_fire_start_indices.append(i)\n",
    "\n",
    "#     # --- Start of sampling logic (your core strategy) ---\n",
    "#     num_fire_samples = len(fire_start_indices)\n",
    "    \n",
    "#     if num_fire_samples == 0:\n",
    "#         print(\"Warning: No fire events found in the dataset. Training will be difficult.\")\n",
    "#         # If no fires, take a small sample of non-fire indices\n",
    "#         num_non_fire_samples_to_use = min(len(non_fire_start_indices), 1000)\n",
    "#     else:\n",
    "#         # Calculate how many non-fire samples to use to achieve the desired ratio\n",
    "#         num_non_fire_samples_to_use = int((num_fire_samples / fire_ratio) - num_fire_samples)\n",
    "#         num_non_fire_samples_to_use = min(num_non_fire_samples_to_use, len(non_fire_start_indices))\n",
    "\n",
    "#     # Sample the indices to create a balanced list\n",
    "#     # The crucial change is ensuring all indices are integers.\n",
    "#     fire_indices_to_use = np.array(fire_start_indices, dtype=int)\n",
    "#     non_fire_indices_to_use = np.random.choice(\n",
    "#         non_fire_start_indices,\n",
    "#         size=num_non_fire_samples_to_use,\n",
    "#         replace=False\n",
    "#     ).astype(int)  # Ensure non-fire indices are also integers\n",
    "    \n",
    "#     indices_to_use = np.concatenate([fire_indices_to_use, non_fire_indices_to_use])\n",
    "#     np.random.shuffle(indices_to_use)\n",
    "    \n",
    "#     # --- End of sampling logic ---\n",
    "    \n",
    "#     for i in indices_to_use:\n",
    "#         # 'i' is now guaranteed to be an integer, preventing the TypeError\n",
    "#         seq_rows = df.iloc[i : i + SEQ_LEN]\n",
    "#         horizon_rows = df.iloc[i + SEQ_LEN : i + SEQ_LEN + HORIZONS]\n",
    "        \n",
    "#         X, y = build_sample(seq_rows, horizon_rows, cache)\n",
    "        \n",
    "#         yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afdf22cf-fdf9-4d61-920d-8afba9b072c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_generator(df, cache, fire_ratio=0.5):\n",
    "    \n",
    "#     valid_start_indices = list(range(len(df) - SEQ_LEN - HORIZONS + 1))\n",
    "\n",
    "#     fire_start_indices = []\n",
    "#     non_fire_start_indices = []\n",
    "    \n",
    "#     for i in valid_start_indices:\n",
    "#         horizon_rows = df.iloc[i + SEQ_LEN : i + SEQ_LEN + HORIZONS]\n",
    "#         has_fire = any(np.any(cache[row[\"viirs_file\"]] > 0) for _, row in horizon_rows.iterrows())\n",
    "        \n",
    "#         if has_fire:\n",
    "#             fire_start_indices.append(i)\n",
    "#         else:\n",
    "#             non_fire_start_indices.append(i)\n",
    "\n",
    "    \n",
    "#     num_fire_samples = len(fire_start_indices)\n",
    "    \n",
    "#     if num_fire_samples == 0:\n",
    "#         print(\"Warning: No fire events found in the dataset. Training will be difficult.\")\n",
    "        \n",
    "#         num_non_fire_samples_to_use = min(len(non_fire_start_indices), 1000) \n",
    "#     else:\n",
    "   \n",
    "#         num_non_fire_samples_to_use = int((num_fire_samples / fire_ratio) - num_fire_samples)\n",
    "#         num_non_fire_samples_to_use = min(num_non_fire_samples_to_use, len(non_fire_start_indices))\n",
    "\n",
    "#     # 4. Sample the indices to create a balanced list\n",
    "#     fire_indices_to_use = fire_start_indices\n",
    "#     non_fire_indices_to_use = np.random.choice(\n",
    "#         non_fire_start_indices,\n",
    "#         size=num_non_fire_samples_to_use,\n",
    "#         replace=False \n",
    "#     )\n",
    "    \n",
    "#     indices_to_use = np.concatenate([fire_indices_to_use, non_fire_indices_to_use])\n",
    "#     np.random.shuffle(indices_to_use)\n",
    "#     indices_to_use = indices_to_use.astype(int) # Add this line to fix the type\n",
    "    \n",
    "#     for i in indices_to_use:\n",
    "#         seq_rows = df.iloc[i : i + SEQ_LEN]\n",
    "#         horizon_rows = df.iloc[i + SEQ_LEN : i + SEQ_LEN + HORIZONS]\n",
    "\n",
    "        \n",
    "#         X, y = build_sample(seq_rows, horizon_rows, cache)\n",
    "        \n",
    "#         yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32da5b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(df, cache, fire_ratio=0.5):\n",
    "    valid_start_indices = list(range(len(df) - SEQ_LEN - HORIZONS + 1))\n",
    "    fire_start_indices = []\n",
    "    non_fire_start_indices = []\n",
    "    \n",
    "    print(\"Scanning data for fire and non-fire events...\")\n",
    "    for i in valid_start_indices:\n",
    "        horizon_rows = df.iloc[i + SEQ_LEN : i + SEQ_LEN + HORIZONS]\n",
    "        has_fire = any(np.any(cache[row[\"viirs_file\"]] > 0) for _, row in horizon_rows.iterrows())\n",
    "        \n",
    "        if has_fire:\n",
    "            fire_start_indices.append(i)\n",
    "        else:\n",
    "            non_fire_start_indices.append(i)\n",
    "\n",
    "    num_fire_samples = len(fire_start_indices)\n",
    "    \n",
    "    if num_fire_samples == 0:\n",
    "        print(\"Warning: No fire events found in the dataset.\")\n",
    "        num_non_fire_samples_to_use = min(len(non_fire_start_indices), 1000) \n",
    "    else:\n",
    "        num_non_fire_samples_to_use = int((num_fire_samples / fire_ratio) - num_fire_samples)\n",
    "        num_non_fire_samples_to_use = min(num_non_fire_samples_to_use, len(non_fire_start_indices))\n",
    "\n",
    "    fire_indices_to_use = fire_start_indices\n",
    "\n",
    "    if len(non_fire_start_indices) > 0 and num_non_fire_samples_to_use > 0:\n",
    "      non_fire_indices_to_use = np.random.choice(\n",
    "          non_fire_start_indices,\n",
    "          size=num_non_fire_samples_to_use,\n",
    "          replace=False \n",
    "      )\n",
    "      indices_to_use = np.concatenate([fire_indices_to_use, non_fire_indices_to_use])\n",
    "    else:\n",
    "      indices_to_use = np.array(fire_indices_to_use)\n",
    "\n",
    "    np.random.shuffle(indices_to_use)\n",
    "    indices_to_use = indices_to_use.astype(int)\n",
    "    \n",
    "    print(f\"Generator initialized. Found {len(fire_indices_to_use)} fire samples and using {len(indices_to_use) - len(fire_indices_to_use)} non-fire samples.\")\n",
    "\n",
    "    for i in indices_to_use:\n",
    "        seq_rows = df.iloc[i : i + SEQ_LEN]\n",
    "        horizon_rows = df.iloc[i + SEQ_LEN : i + SEQ_LEN + HORIZONS]\n",
    "        X, y = build_sample(seq_rows, horizon_rows, cache)\n",
    "        yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbccc812-c0bf-4446-9bbe-8e352a0c2ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_dataset(df, cache, shuffle_buf=256):\n",
    "#     output_signature = (\n",
    "#         tf.TensorSpec(shape=(SEQ_LEN, PATCH_SIZE, PATCH_SIZE, 7), dtype=tf.float32),\n",
    "#         tf.TensorSpec(shape=(HORIZONS, PATCH_SIZE, PATCH_SIZE), dtype=tf.float32),\n",
    "#     )\n",
    "    \n",
    "#     ds = tf.data.Dataset.from_generator(\n",
    "#         lambda: make_generator(df, cache),\n",
    "#         output_signature=output_signature\n",
    "#     )\n",
    "    \n",
    "#     ds = ds.shuffle(shuffle_buf, reshuffle_each_iteration=True)\n",
    "#     ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "#     return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d67068e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df, cache, shuffle=True, ensure_fire=True, shuffle_buf=256):\n",
    "    output_signature = (\n",
    "        tf.TensorSpec(shape=(SEQ_LEN, PATCH_SIZE, PATCH_SIZE, 7), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(HORIZONS, PATCH_SIZE, PATCH_SIZE), dtype=tf.float32),\n",
    "    )\n",
    "    \n",
    "    # CORRECTED LINE:\n",
    "    # Changed the keyword argument from 'ensure_fire=' to 'fire_ratio='\n",
    "    # This now correctly passes the value to the make_generator function.\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        lambda: make_generator(df, cache, fire_ratio=ensure_fire),\n",
    "        output_signature=output_signature\n",
    "    )\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_buf, reshuffle_each_iteration=True)\n",
    "    \n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e327f91e-e454-4b6c-8ea4-f6b8b6aae545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 17535\n",
      "Train samples: 14028\n",
      "Validation samples: 3507\n",
      "Loading rasters into memory...\n",
      "Loaded 9 rasters into memory ✅\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    csv_path = r\"C:\\Users\\Ankit\\Datasets_Forest_fire\\sequence_index_hourly_binary.csv\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    TOTAL = len(df)\n",
    "    VAL_SPLIT = 0.2\n",
    "    val_size = int(TOTAL * VAL_SPLIT)\n",
    "\n",
    "    val_df = df.iloc[:val_size].copy()\n",
    "    train_df = df.iloc[val_size:].copy()\n",
    "\n",
    "    print(f\"Total samples: {TOTAL}\")\n",
    "    print(f\"Train samples: {len(train_df)}\")\n",
    "    print(f\"Validation samples: {len(val_df)}\")\n",
    "\n",
    "    raster_cols = REQUIRED_COLS\n",
    "    print(\"Loading rasters into memory...\")\n",
    "    cache = load_rasters(df, raster_cols, max_workers=8)\n",
    "    print(f\"Loaded {len(cache)} rasters into memory ✅\")\n",
    "\n",
    "    # Use the new, balanced dataset functions\n",
    "    train_dataset = create_dataset(train_df, cache)\n",
    "    val_dataset = create_dataset(val_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57d42604-5193-4582-b7a9-80bc3595e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a467883b-f9ba-44cb-8ffe-1110e5ef2f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c9866-8427-4506-a99a-284d6c3d7964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259f3ef4-6903-4f80-b057-8d0d44d4f238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90893721-b56d-4630-b86d-cf7a92ef7fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e700a567-9a37-440c-9e04-d691f0824fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 6           \n",
    "PATCH_H = 13            \n",
    "PATCH_W = 13          \n",
    "CHANNELS = 7       \n",
    "HORIZONS = 3            \n",
    "LSTM_UNITS = 64    \n",
    "CNN_FEATURES = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27354090-4f0c-46e7-a8d1-0d0897ea2f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "# def build_conv_lstm_unet_model(\n",
    "#     seq_len=SEQ_LEN,\n",
    "#     patch_h=PATCH_H,\n",
    "#     patch_w=PATCH_W,\n",
    "#     channels=CHANNELS,\n",
    "#     horizons=HORIZONS\n",
    "# ):\n",
    "#     inp = layers.Input(shape=(seq_len, patch_h, patch_w, channels))\n",
    "\n",
    "#     enc1 = layers.ConvLSTM2D(\n",
    "#         filters=32, kernel_size=(3, 3), padding='same', return_sequences=True, activation='relu'\n",
    "#     )(inp)\n",
    "#     enc1_pool = layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same')(enc1)\n",
    "\n",
    "#     enc2 = layers.ConvLSTM2D(\n",
    "#         filters=64, kernel_size=(3, 3), padding='same', return_sequences=True, activation='relu'\n",
    "#     )(enc1_pool)\n",
    "#     enc2_pool = layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same')(enc2)\n",
    "\n",
    "#     bottleneck = layers.ConvLSTM2D(\n",
    "#         filters=128, kernel_size=(3, 3), padding='same', return_sequences=True, activation='relu'\n",
    "#     )(enc2_pool)\n",
    "\n",
    "#     dec1_up = layers.UpSampling3D(size=(1, 2, 2))(bottleneck)\n",
    "#     dec1_up = layers.Conv3D(filters=64, kernel_size=(3,3,3), padding='same', activation='relu')(dec1_up)\n",
    "#     dec1_up_cropped = layers.Cropping3D(cropping=((0, 0), (0, 1), (0, 1)))(dec1_up)\n",
    "#     dec1_concat = layers.Concatenate(axis=-1)([dec1_up_cropped, enc2])\n",
    "\n",
    "#     dec2_up = layers.UpSampling3D(size=(1, 2, 2))(dec1_concat)\n",
    "#     dec2_up = layers.Conv3D(filters=32, kernel_size=(3,3,3), padding='same', activation='relu')(dec2_up)\n",
    "#     dec2_up_cropped = layers.Cropping3D(cropping=((0, 0), (0, 1), (0, 1)))(dec2_up)\n",
    "#     dec2_concat = layers.Concatenate(axis=-1)([dec2_up_cropped, enc1])\n",
    "\n",
    "#     output_convlstm = layers.ConvLSTM2D(\n",
    "#         filters=1, kernel_size=(3, 3), padding='same', return_sequences=True, activation='sigmoid'\n",
    "#     )(dec2_concat[:, :horizons])\n",
    "\n",
    "#     final_output = tf.keras.ops.squeeze(output_convlstm, axis=-1)\n",
    "\n",
    "#     model = models.Model(inputs=inp, outputs=final_output)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "638c407e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PATCH_H' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msqueeze_output_shape\u001b[39m(input_shape):\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m input_shape[:-\u001b[32m1\u001b[39m] \n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_conv_lstm_unet_model\u001b[39m(\n\u001b[32m     17\u001b[39m     seq_len=SEQ_LEN,\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     patch_h=\u001b[43mPATCH_H\u001b[49m,\n\u001b[32m     19\u001b[39m     patch_w=PATCH_W,\n\u001b[32m     20\u001b[39m     channels=CHANNELS,\n\u001b[32m     21\u001b[39m     horizons=HORIZONS\n\u001b[32m     22\u001b[39m ):\n\u001b[32m     23\u001b[39m     inp = layers.Input(shape=(seq_len, patch_h, patch_w, channels))\n\u001b[32m     25\u001b[39m     enc1 = layers.ConvLSTM2D(filters=\u001b[32m32\u001b[39m, kernel_size=(\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), padding=\u001b[33m'\u001b[39m\u001b[33msame\u001b[39m\u001b[33m'\u001b[39m, return_sequences=\u001b[38;5;28;01mTrue\u001b[39;00m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m)(inp)\n",
      "\u001b[31mNameError\u001b[39m: name 'PATCH_H' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "def slice_output_func(x):\n",
    "    return x[:, :HORIZONS, :, :, :]\n",
    "\n",
    "def slice_output_shape(input_shape):\n",
    "    return (input_shape[0], HORIZONS, input_shape[2], input_shape[3], input_shape[4])\n",
    "\n",
    "def squeeze_output_func(x):\n",
    "    return tf.squeeze(x, axis=-1)\n",
    "\n",
    "def squeeze_output_shape(input_shape):\n",
    "    return input_shape[:-1] \n",
    "\n",
    "def build_conv_lstm_unet_model(\n",
    "    seq_len=SEQ_LEN,\n",
    "    patch_h=PATCH_H,\n",
    "    patch_w=PATCH_W,\n",
    "    channels=CHANNELS,\n",
    "    horizons=HORIZONS\n",
    "):\n",
    "    inp = layers.Input(shape=(seq_len, patch_h, patch_w, channels))\n",
    "\n",
    "    enc1 = layers.ConvLSTM2D(filters=32, kernel_size=(3, 3), padding='same', return_sequences=True, activation='relu')(inp)\n",
    "    enc1_pool = layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same')(enc1)\n",
    "\n",
    "    enc2 = layers.ConvLSTM2D(filters=64, kernel_size=(3, 3), padding='same', return_sequences=True, activation='relu')(enc1_pool)\n",
    "    enc2_pool = layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same')(enc2)\n",
    "\n",
    "    bottleneck = layers.ConvLSTM2D(filters=128, kernel_size=(3, 3), padding='same', return_sequences=True, activation='relu')(enc2_pool)\n",
    "\n",
    "    dec1_up = layers.UpSampling3D(size=(1, 2, 2))(bottleneck)\n",
    "    dec1_up = layers.Conv3D(filters=64, kernel_size=(3,3,3), padding='same', activation='relu')(dec1_up)\n",
    "    dec1_up_cropped = layers.Cropping3D(cropping=((0, 0), (0, 1), (0, 1)))(dec1_up)\n",
    "    dec1_concat = layers.Concatenate(axis=-1)([dec1_up_cropped, enc2])\n",
    "\n",
    "    dec2_up = layers.UpSampling3D(size=(1, 2, 2))(dec1_concat)\n",
    "    dec2_up = layers.Conv3D(filters=32, kernel_size=(3,3,3), padding='same', activation='relu')(dec2_up)\n",
    "    dec2_up_cropped = layers.Cropping3D(cropping=((0, 0), (0, 1), (0, 1)))(dec2_up)\n",
    "    dec2_concat = layers.Concatenate(axis=-1)([dec2_up_cropped, enc1])\n",
    "\n",
    "    output_convlstm = layers.ConvLSTM2D(\n",
    "        filters=1, kernel_size=(3, 3), padding='same', return_sequences=True, activation='sigmoid'\n",
    "    )(dec2_concat)\n",
    "\n",
    "    output_sliced = layers.Lambda(\n",
    "        slice_output_func, \n",
    "        output_shape=slice_output_shape,\n",
    "        name='output_slicer'\n",
    "    )(output_convlstm)\n",
    "\n",
    "    final_output = layers.Lambda(\n",
    "        squeeze_output_func,\n",
    "        output_shape=squeeze_output_shape,\n",
    "        name='final_squeeze'\n",
    "    )(output_sliced)\n",
    "    \n",
    "    model = models.Model(inputs=inp, outputs=final_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e92766c1-8599-4ad5-8b12-7b77371b345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd2f64e9-74fb-4b7c-9ffc-de3555b0238c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv_lstm2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">45,056</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv_lstm2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv_lstm2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">221,440</span> │ max_pooling3d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling3d_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv_lstm2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv_lstm2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">885,248</span> │ max_pooling3d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ up_sampling3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling3D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv_lstm2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">221,248</span> │ up_sampling3d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cropping3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cropping3D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cropping3d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
       "│                               │                           │                 │ conv_lstm2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ up_sampling3d_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling3D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">110,624</span> │ up_sampling3d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cropping3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cropping3D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cropping3d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│                               │                           │                 │ conv_lstm2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv_lstm2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,344</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ output_slicer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv_lstm2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ final_squeeze (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ output_slicer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m7\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv_lstm2d (\u001b[38;5;33mConvLSTM2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m45,056\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling3d (\u001b[38;5;33mMaxPooling3D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ conv_lstm2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv_lstm2d_1 (\u001b[38;5;33mConvLSTM2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m221,440\u001b[0m │ max_pooling3d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling3d_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ conv_lstm2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMaxPooling3D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv_lstm2d_2 (\u001b[38;5;33mConvLSTM2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m885,248\u001b[0m │ max_pooling3d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ up_sampling3d (\u001b[38;5;33mUpSampling3D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │ conv_lstm2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv3d (\u001b[38;5;33mConv3D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m221,248\u001b[0m │ up_sampling3d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cropping3d (\u001b[38;5;33mCropping3D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ conv3d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │ cropping3d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
       "│                               │                           │                 │ conv_lstm2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ up_sampling3d_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │               \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mUpSampling3D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv3d_1 (\u001b[38;5;33mConv3D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m110,624\u001b[0m │ up_sampling3d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cropping3d_1 (\u001b[38;5;33mCropping3D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │ conv3d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_1 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │ cropping3d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│                               │                           │                 │ conv_lstm2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv_lstm2d_3 (\u001b[38;5;33mConvLSTM2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │           \u001b[38;5;34m2,344\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ output_slicer (\u001b[38;5;33mLambda\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │ conv_lstm2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ final_squeeze (\u001b[38;5;33mLambda\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ output_slicer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,485,960</span> (5.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,485,960\u001b[0m (5.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,485,960</span> (5.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,485,960\u001b[0m (5.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_conv_lstm_unet_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "040d3ca1-db4a-4d5d-ae17-2848bcbeaa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.AUC()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f87cb8a8-b977-489f-a3cd-e8e4d93cad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    \"best_unet_model.keras\", # Changed filename\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d1ac3e8-da0e-47ab-b52a-b15d24e239e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 16\n",
      "Steps per epoch: 876\n",
      "Validation steps: 219\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "steps_per_epoch = len(train_df) // BATCH_SIZE\n",
    "validation_steps = len(val_df) // BATCH_SIZE\n",
    "\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Validation steps: {validation_steps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54aacb94-0770-44f8-bd4f-ea2f79b1cf3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 14020 fire samples and using 0 non-fire samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758646730.610202  409982 service.cc:152] XLA service 0x7f98440068e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1758646730.610219  409982 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 5060 Ti, Compute Capability 12.0\n",
      "2025-09-23 22:28:50.874322: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1758646731.834813  409982 cuda_dnn.cc:529] Loaded cuDNN version 91100\n",
      "I0000 00:00:1758646739.310925  409982 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m875/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - auc: 0.5325 - binary_accuracy: 0.9954 - loss: 0.0911Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 1: val_loss improved from None to 0.03133, saving model to best_unet_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 35ms/step - auc: 0.5720 - binary_accuracy: 0.9952 - loss: 0.0463 - val_auc: 0.6382 - val_binary_accuracy: 0.9948 - val_loss: 0.0313\n",
      "Epoch 2/50\n",
      "\u001b[1m  1/876\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:45\u001b[0m 5s/step - auc: 0.6670 - binary_accuracy: 0.9778 - loss: 0.1131Scanning data for fire and non-fire events...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 22:29:35.866010: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-09-23 22:29:35.866024: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "/usr/lib/python3.13/site-packages/keras/src/trainers/epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.03133\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - auc: 0.6670 - binary_accuracy: 0.9778 - loss: 0.1131 - val_auc: 0.6441 - val_binary_accuracy: 0.9948 - val_loss: 0.0315\n",
      "Epoch 3/50\n",
      "Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 14020 fire samples and using 0 non-fire samples.\n",
      "\u001b[1m874/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - auc: 0.6292 - binary_accuracy: 0.9950 - loss: 0.0304Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 3: val_loss improved from 0.03133 to 0.03108, saving model to best_unet_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 29ms/step - auc: 0.6344 - binary_accuracy: 0.9952 - loss: 0.0293 - val_auc: 0.6588 - val_binary_accuracy: 0.9948 - val_loss: 0.0311\n",
      "Epoch 4/50\n",
      "\u001b[1m  1/876\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - auc: 0.6925 - binary_accuracy: 0.9951 - loss: 0.0292Scanning data for fire and non-fire events...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 22:30:11.368007: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 4: val_loss improved from 0.03108 to 0.03108, saving model to best_unet_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - auc: 0.6925 - binary_accuracy: 0.9951 - loss: 0.0292 - val_auc: 0.6583 - val_binary_accuracy: 0.9948 - val_loss: 0.0311\n",
      "Epoch 5/50\n",
      "Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 14020 fire samples and using 0 non-fire samples.\n",
      "\u001b[1m874/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - auc: 0.6372 - binary_accuracy: 0.9953 - loss: 0.0288Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.03108\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 29ms/step - auc: 0.6404 - binary_accuracy: 0.9952 - loss: 0.0292 - val_auc: 0.6435 - val_binary_accuracy: 0.9948 - val_loss: 0.0311\n",
      "Epoch 6/50\n",
      "\u001b[1m  1/876\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - auc: 0.7481 - binary_accuracy: 0.9995 - loss: 0.0070Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 6: val_loss improved from 0.03108 to 0.03105, saving model to best_unet_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - auc: 0.7481 - binary_accuracy: 0.9995 - loss: 0.0070 - val_auc: 0.6473 - val_binary_accuracy: 0.9948 - val_loss: 0.0310\n",
      "Epoch 7/50\n",
      "Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 14020 fire samples and using 0 non-fire samples.\n",
      "\u001b[1m875/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - auc: 0.6443 - binary_accuracy: 0.9952 - loss: 0.0291Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 7: val_loss improved from 0.03105 to 0.03104, saving model to best_unet_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - auc: 0.6407 - binary_accuracy: 0.9952 - loss: 0.0292 - val_auc: 0.6412 - val_binary_accuracy: 0.9948 - val_loss: 0.0310\n",
      "Epoch 8/50\n",
      "\u001b[1m  1/876\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - auc: 0.8134 - binary_accuracy: 0.9985 - loss: 0.0117Scanning data for fire and non-fire events...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 22:31:21.564035: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 8: val_loss improved from 0.03104 to 0.03102, saving model to best_unet_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - auc: 0.8134 - binary_accuracy: 0.9985 - loss: 0.0117 - val_auc: 0.6416 - val_binary_accuracy: 0.9948 - val_loss: 0.0310\n",
      "Epoch 9/50\n",
      "Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 14020 fire samples and using 0 non-fire samples.\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - auc: 0.6381 - binary_accuracy: 0.9951 - loss: 0.0295Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 9: val_loss improved from 0.03102 to 0.03095, saving model to best_unet_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - auc: 0.6386 - binary_accuracy: 0.9952 - loss: 0.0292 - val_auc: 0.6609 - val_binary_accuracy: 0.9948 - val_loss: 0.0310\n",
      "Epoch 10/50\n",
      "\u001b[1m  1/876\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - auc: 0.6794 - binary_accuracy: 0.9990 - loss: 0.0100Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.03095\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - auc: 0.6794 - binary_accuracy: 0.9990 - loss: 0.0100 - val_auc: 0.6525 - val_binary_accuracy: 0.9948 - val_loss: 0.0310\n",
      "Epoch 11/50\n",
      "Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 14020 fire samples and using 0 non-fire samples.\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - auc: 0.6441 - binary_accuracy: 0.9955 - loss: 0.0276Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.03095\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - auc: 0.6505 - binary_accuracy: 0.9952 - loss: 0.0291 - val_auc: 0.6464 - val_binary_accuracy: 0.9948 - val_loss: 0.0310\n",
      "Epoch 12/50\n",
      "\u001b[1m  1/876\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - auc: 0.0000e+00 - binary_accuracy: 1.0000 - loss: 0.0045Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.03095\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - auc: 0.0000e+00 - binary_accuracy: 1.0000 - loss: 0.0045 - val_auc: 0.6444 - val_binary_accuracy: 0.9948 - val_loss: 0.0310\n",
      "Epoch 13/50\n",
      "Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 14020 fire samples and using 0 non-fire samples.\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - auc: 0.6550 - binary_accuracy: 0.9951 - loss: 0.0294Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 13: val_loss improved from 0.03095 to 0.03090, saving model to best_unet_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - auc: 0.6511 - binary_accuracy: 0.9952 - loss: 0.0291 - val_auc: 0.6732 - val_binary_accuracy: 0.9948 - val_loss: 0.0309\n",
      "Epoch 14/50\n",
      "\u001b[1m  1/876\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - auc: 0.6392 - binary_accuracy: 0.9990 - loss: 0.0104Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.03090\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - auc: 0.6392 - binary_accuracy: 0.9990 - loss: 0.0104 - val_auc: 0.6739 - val_binary_accuracy: 0.9948 - val_loss: 0.0309\n",
      "Epoch 15/50\n",
      "Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 14020 fire samples and using 0 non-fire samples.\n",
      "\u001b[1m875/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - auc: 0.6552 - binary_accuracy: 0.9953 - loss: 0.0284Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.03090\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - auc: 0.6529 - binary_accuracy: 0.9952 - loss: 0.0291 - val_auc: 0.6148 - val_binary_accuracy: 0.9948 - val_loss: 0.0313\n",
      "Epoch 16/50\n",
      "\u001b[1m  1/876\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - auc: 0.0000e+00 - binary_accuracy: 1.0000 - loss: 0.0038Scanning data for fire and non-fire events...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 22:33:44.002168: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2025-09-23 22:33:44.002192: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 2109665068740041596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.03090\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - auc: 0.0000e+00 - binary_accuracy: 1.0000 - loss: 0.0038 - val_auc: 0.6127 - val_binary_accuracy: 0.9948 - val_loss: 0.0314\n",
      "Epoch 17/50\n",
      "Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 14020 fire samples and using 0 non-fire samples.\n",
      "\u001b[1m874/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - auc: 0.6493 - binary_accuracy: 0.9952 - loss: 0.0291Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.03090\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - auc: 0.6548 - binary_accuracy: 0.9952 - loss: 0.0290 - val_auc: 0.6326 - val_binary_accuracy: 0.9948 - val_loss: 0.0311\n",
      "Epoch 18/50\n",
      "\u001b[1m  1/876\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - auc: 0.0000e+00 - binary_accuracy: 1.0000 - loss: 0.0040Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.03090\n",
      "\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - auc: 0.0000e+00 - binary_accuracy: 1.0000 - loss: 0.0040 - val_auc: 0.6272 - val_binary_accuracy: 0.9948 - val_loss: 0.0311\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop, checkpoint],\n",
    "    verbose=1,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "661fed53-7207-48fe-a419-c91be0405b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "\n",
      "[CRITICAL WARNING] 'val_dataset' is not available. Generating a report requires your validation data.\n",
      "Please ensure your data loading cells from the original notebook are executed.\n",
      "\n",
      "--- Generating Classification Report ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Generating Classification Report ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# a. Run predictions on the full validation dataset\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Setting verbose=0 silences the progress bar\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m y_pred_probs = model.predict(\u001b[43mval_dataset\u001b[49m, verbose=\u001b[32m0\u001b[39m) \n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# b. Get true labels. We need to iterate through the dataset to get all labels.\u001b[39;00m\n\u001b[32m     72\u001b[39m y_true_list = []\n",
      "\u001b[31mNameError\u001b[39m: name 'val_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import classification_report # Requires: pip install scikit-learn\n",
    "\n",
    "# --- 1. Define Global Variables (CRITICAL) ---\n",
    "# These values are needed by the custom functions and to shape the targets.\n",
    "SEQ_LEN = 6\n",
    "HORIZONS = 3\n",
    "PATCH_H = 13\n",
    "PATCH_W = 13\n",
    "CHANNELS = 7\n",
    "\n",
    "# --- 2. Define Custom Functions (CRITICAL for Model Loading) ---\n",
    "# These functions must be present in the namespace.\n",
    "\n",
    "def slice_output_func(x):\n",
    "    return x[:, :HORIZONS, :, :, :] \n",
    "\n",
    "def squeeze_output_func(x):\n",
    "    return tf.squeeze(x, axis=-1)\n",
    "\n",
    "# Define shape functions (needed by the H5 format model)\n",
    "def slice_output_shape(input_shape):\n",
    "    return (input_shape[0], HORIZONS, input_shape[2], input_shape[3], input_shape[4])\n",
    "\n",
    "def squeeze_output_shape(input_shape):\n",
    "    return input_shape[:-1] \n",
    "\n",
    "CUSTOM_OBJECTS = {\n",
    "    'slice_output_func': slice_output_func,\n",
    "    'slice_output_shape': slice_output_shape,\n",
    "    'squeeze_output_func': squeeze_output_func,\n",
    "    'squeeze_output_shape': squeeze_output_shape,\n",
    "    'output_slicer': layers.Lambda(slice_output_func, output_shape=slice_output_shape, name='output_slicer'),\n",
    "    'final_squeeze': layers.Lambda(squeeze_output_func, output_shape=squeeze_output_shape, name='final_squeeze'),\n",
    "} \n",
    "\n",
    "MODEL_PATH = r\"C:\\Users\\Ankit\\Downloads\\best_unet_model (2).h5\" \n",
    "\n",
    "# --- 3. Load the Model ---\n",
    "try:\n",
    "    model = tf.keras.models.load_model(\n",
    "        MODEL_PATH, \n",
    "        custom_objects=CUSTOM_OBJECTS,\n",
    "        safe_mode=False # Still needed for legacy H5 Lambda layers\n",
    "    )\n",
    "    print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n[ERROR] Failed to load model: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 4. Prediction and Report Generation ---\n",
    "\n",
    "# Note: The 'val_dataset' must be defined and available from your prior data loading code.\n",
    "if 'val_dataset' not in locals():\n",
    "    print(\"\\n[CRITICAL WARNING] 'val_dataset' is not available. Generating a report requires your validation data.\")\n",
    "    print(\"Please ensure your data loading cells from the original notebook are executed.\")\n",
    "    # For demonstration, we will use a small prediction sample if available\n",
    "    # Assuming you have the val_dataset iterator from your previous steps:\n",
    "    # X_val, y_val = next(iter(val_dataset)) # Uncomment this if you can access your dataset\n",
    "    exit()\n",
    "\n",
    "\n",
    "print(\"\\n--- Generating Classification Report ---\")\n",
    "\n",
    "# a. Run predictions on the full validation dataset\n",
    "# Setting verbose=0 silences the progress bar\n",
    "y_pred_probs = model.predict(val_dataset, verbose=0) \n",
    "\n",
    "# b. Get true labels. We need to iterate through the dataset to get all labels.\n",
    "y_true_list = []\n",
    "for _, y_batch in val_dataset:\n",
    "    y_true_list.append(y_batch.numpy())\n",
    "\n",
    "y_true = np.concatenate(y_true_list, axis=0)\n",
    "\n",
    "# c. Flatten the arrays and convert probabilities to binary labels (0 or 1)\n",
    "# The prediction shape is (N_samples, HORIZONS, H, W). We flatten it to a single list of pixels.\n",
    "y_true_flat = y_true.flatten()\n",
    "\n",
    "# Use a threshold (0.5 is standard) to convert probabilities to classes\n",
    "y_pred_classes_flat = (y_pred_probs.flatten() > 0.5).astype(int)\n",
    "\n",
    "# d. Generate and print the classification report\n",
    "report = classification_report(y_true_flat, y_pred_classes_flat, target_names=['No Fire (0)', 'Fire (1)'])\n",
    "\n",
    "print(report)\n",
    "\n",
    "print(\"--- End of Report ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41646e35-6cc7-4918-9c0e-6a0feaa9294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c7af21d-bb02-4c3c-ae50-27e54b820f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load model after system reboot...\n",
      "\n",
      "[CRITICAL ERROR] Failed to load model even after reboot: [Errno 13] Permission denied: 'C:\\\\Users\\\\Ankit\\\\best_unet_model.keras'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# NOTE: These functions must be defined, as your model structure requires them.\n",
    "def slice_output_func(x):\n",
    "    return x[:, :3, :, :, :] \n",
    "\n",
    "def squeeze_output_func(x):\n",
    "    return tf.squeeze(x, axis=-1)\n",
    "\n",
    "CUSTOM_OBJECTS = {\n",
    "    'output_slicer': slice_output_func,\n",
    "    'final_squeeze': squeeze_output_func,\n",
    "} \n",
    "\n",
    "# Update this path if you used a temporary location like C:\\Temp\n",
    "MODEL_PATH = r\"C:\\Users\\Ankit\\best_unet_model.keras\"\n",
    "\n",
    "try:\n",
    "    print(\"Attempting to load model after system reboot...\")\n",
    "    model = tf.keras.models.load_model(\n",
    "        MODEL_PATH, \n",
    "        custom_objects=CUSTOM_OBJECTS\n",
    "    )\n",
    "    \n",
    "    print(\"\\nModel loaded successfully! The system lock was successfully cleared.\")\n",
    "    model.summary()\n",
    "    \n",
    "except Exception as e:\n",
    "    # If this fails after a clean reboot, there is a fundamental (but rare) \n",
    "    # operating system permission issue you need to fix manually.\n",
    "    print(f\"\\n[CRITICAL ERROR] Failed to load model even after reboot: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd631643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PyTorch and System Information ---\n",
      "PyTorch Version: 2.8.0\n",
      "Python Version: 3.13.7 (main, Aug 15 2025, 12:34:02) [GCC 15.2.1 20250813]\n",
      "\n",
      "--- GPU Detection ---\n",
      "✅ Success! PyTorch has detected 1 CUDA-enabled GPU(s).\n",
      "  GPU [0]: NVIDIA GeForce RTX 5060 Ti (Active)\n",
      "\n",
      "--- Simple GPU Operation Test ---\n",
      "  Attempting to use device: cuda:0 (NVIDIA GeForce RTX 5060 Ti)\n",
      "  Successfully created a tensor on the GPU.\n",
      "  Tensor: tensor([1.5000, 2.5000, 3.5000], device='cuda:0')\n",
      "  Tensor's Device: cuda:0\n",
      "\n",
      "  Performing a simple operation (tensor * 2)...\n",
      "  Result: tensor([3., 5., 7.], device='cuda:0')\n",
      "  Result's Device: cuda:0\n",
      "\n",
      "✅ GPU is working correctly for computations.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "def check_pytorch_gpu():\n",
    "    \"\"\"\n",
    "    Checks for GPU availability in PyTorch, prints details, and runs a test.\n",
    "    \"\"\"\n",
    "    print(f\"--- PyTorch and System Information ---\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"Python Version: {sys.version}\")\n",
    "\n",
    "    # The primary function to check for a CUDA-enabled GPU\n",
    "    is_available = torch.cuda.is_available()\n",
    "\n",
    "    print(f\"\\n--- GPU Detection ---\")\n",
    "    if is_available:\n",
    "        # Get the number of available GPUs\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        print(f\"✅ Success! PyTorch has detected {gpu_count} CUDA-enabled GPU(s).\")\n",
    "\n",
    "        # Print details for each GPU\n",
    "        for i in range(gpu_count):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            current_device_index = torch.cuda.current_device()\n",
    "            # Add a star '*' to indicate the currently active GPU\n",
    "            active_indicator = \" (Active)\" if i == current_device_index else \"\"\n",
    "            print(f\"  GPU [{i}]: {gpu_name}{active_indicator}\")\n",
    "\n",
    "        print(\"\\n--- Simple GPU Operation Test ---\")\n",
    "        try: # 1. Define the device to be the first available GPU\n",
    "            device = torch.device(\"cuda:0\")\n",
    "            print(f\"  Attempting to use device: {device} ({torch.cuda.get_device_name(0)})\")\n",
    "\n",
    "            # 2. Create a sample tensor and move it to the GPU\n",
    "            sample_tensor = torch.tensor([1.5, 2.5, 3.5], device=device)\n",
    "            print(f\"  Successfully created a tensor on the GPU.\")\n",
    "            print(f\"  Tensor: {sample_tensor}\")\n",
    "            print(f\"  Tensor's Device: {sample_tensor.device}\")\n",
    "\n",
    "            # 3. Perform a simple operation\n",
    "            result = sample_tensor * 2\n",
    "            print(\"\\n  Performing a simple operation (tensor * 2)...\")\n",
    "            print(f\"  Result: {result}\")\n",
    "            print(f\"  Result's Device: {result.device}\")\n",
    "            print(\"\\n✅ GPU is working correctly for computations.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ An error occurred during the GPU operation test: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(\"❌ Failure. PyTorch did NOT detect any CUDA-enabled GPUs.\")\n",
    "        print(\"Please check the following:\")\n",
    "        print(\"1. Is a compatible NVIDIA GPU installed?\")\n",
    "        print(\"2. Are the NVIDIA drivers installed correctly? (Check with 'nvidia-smi' in your terminal)\")\n",
    "        print(\"3. Did you install the PyTorch version with CUDA support?\")\n",
    "        print(\"   (e.g., from pytorch.org, select a CUDA option in the install matrix)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_pytorch_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a183aed-a4ce-4e13-a595-989bdad4c688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: C:\\Users\\Ankit\\Downloads\\final_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "\n",
      "--- Searching for a Correct Fire Prediction Sample ---\n",
      "Using prediction threshold: 0.5\n",
      "Scanning data for fire and non-fire events...\n",
      "Generator initialized. Found 3499 fire samples and using 0 non-fire samples.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- 1. Define Global Variables (CRITICAL) ---\n",
    "SEQ_LEN = 6      # Input sequence length (days/timesteps)\n",
    "HORIZONS = 3     # Prediction horizon length (days/timesteps)\n",
    "PATCH_H = 13     # Patch height\n",
    "PATCH_W = 13     # Patch width\n",
    "CHANNELS = 7\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# --- 2. Define Custom Functions (Required for Model Loading) ---\n",
    "# NOTE: These functions must be in the global scope.\n",
    "def slice_output_func(x):\n",
    "    return x[:, :HORIZONS, :, :, :] \n",
    "\n",
    "def squeeze_output_func(x):\n",
    "    return tf.squeeze(x, axis=-1)\n",
    "\n",
    "def slice_output_shape(input_shape):\n",
    "    return (input_shape[0], HORIZONS, input_shape[2], input_shape[3], input_shape[4])\n",
    "\n",
    "def squeeze_output_shape(input_shape):\n",
    "    return input_shape[:-1] \n",
    "\n",
    "CUSTOM_OBJECTS = {\n",
    "    'slice_output_func': slice_output_func,\n",
    "    'slice_output_shape': slice_output_shape,\n",
    "    'squeeze_output_func': squeeze_output_func,\n",
    "    'squeeze_output_shape': squeeze_output_shape,\n",
    "    'output_slicer': layers.Lambda(slice_output_func, output_shape=slice_output_shape, name='output_slicer'),\n",
    "    'final_squeeze': layers.Lambda(squeeze_output_func, output_shape=squeeze_output_shape, name='final_squeeze'),\n",
    "} \n",
    "\n",
    "# --- 3. Model Loading ---\n",
    "MODEL_PATH = r\"C:\\Users\\Ankit\\Downloads\\final_model.h5\"\n",
    "try:\n",
    "    print(f\"Loading model from: {MODEL_PATH}\")\n",
    "    model = tf.keras.models.load_model(\n",
    "        MODEL_PATH, \n",
    "        custom_objects=CUSTOM_OBJECTS,\n",
    "        safe_mode=False \n",
    "    )\n",
    "    print(\"Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n[CRITICAL ERROR] Failed to load model: {e}\")\n",
    "    sys.exit(1) # Exit if model load fails\n",
    "\n",
    "\n",
    "# --- 4. Define Helper Functions for Date/Time Mapping ---\n",
    "\n",
    "def get_sample_date_range(start_index, df):\n",
    "    \"\"\"Calculates the date range for a given sample index.\"\"\"\n",
    "    # The start date for the dataset (January 1, 2015)\n",
    "    START_DATE = datetime(2015, 1, 1)\n",
    "    \n",
    "    # Each row in your sequence_index_hourly_binary.csv represents one hour (based on context).\n",
    "    # The 'start_index' corresponds to the index in the original DataFrame (df).\n",
    "    \n",
    "    # The prediction starts at the hour corresponding to the end of the input sequence.\n",
    "    pred_start_index = start_index + SEQ_LEN\n",
    "    pred_end_index = pred_start_index + HORIZONS - 1\n",
    "    \n",
    "    # Calculate the datetime objects\n",
    "    pred_start_time = START_DATE + timedelta(hours=int(df.iloc[pred_start_index]['index']))\n",
    "    pred_end_time = START_DATE + timedelta(hours=int(df.iloc[pred_end_index]['index']))\n",
    "    \n",
    "    return pred_start_time.strftime('%Y-%m-%d %H:%M:%S'), pred_end_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "# --- 5. Find Successful Fire Prediction ---\n",
    "\n",
    "# --- CRITICAL ASSUMPTIONS ---\n",
    "# 1. 'train_df' and 'val_df' (DataFrames used for creating the datasets) are available.\n",
    "# 2. 'val_dataset' (TensorFlow Dataset iterator) is available and correctly setup.\n",
    "# 3. 'df' (the original, unshuffled, full DataFrame) is available if you want to map back to original indices.\n",
    "\n",
    "# Since we can't rely on global variables in this environment, we'll try to find the starting index \n",
    "# and report the prediction. The logic is self-contained below.\n",
    "\n",
    "# --- Finding the Correct Prediction ---\n",
    "FIRE_PREDICTION_FOUND = False\n",
    "THRESHOLD = 0.5\n",
    "sample_counter = 0\n",
    "\n",
    "print(\"\\n--- Searching for a Correct Fire Prediction Sample ---\")\n",
    "print(f\"Using prediction threshold: {THRESHOLD}\")\n",
    "\n",
    "\n",
    "# We need to recreate a simplified generator/iterator logic here if we can't access val_dataset.\n",
    "# ASSUMING: You have already run the data loading cells and have the actual 'val_dataset'\n",
    "# If not, this script WILL FAIL at the 'val_dataset' iteration.\n",
    "\n",
    "for X_batch, Y_true_batch in val_dataset.unbatch().batch(1): # Iterate one sample at a time\n",
    "    \n",
    "    # 1. Get the prediction\n",
    "    Y_pred_batch = model.predict(X_batch, verbose=0)\n",
    "    \n",
    "    # 2. Convert prediction probabilities to binary class (0 or 1)\n",
    "    Y_pred_classes = (Y_pred_batch > THRESHOLD).astype(int)\n",
    "    \n",
    "    # 3. Check for a True Positive (TP): Ground Truth is Fire (1) AND Prediction is Fire (1)\n",
    "    # The true fire samples are where Y_true_batch > 0 \n",
    "    \n",
    "    # Check if the ground truth contains *any* fire pixel\n",
    "    is_fire_in_true = np.any(Y_true_batch.numpy() > 0)\n",
    "    \n",
    "    if is_fire_in_true:\n",
    "        # Check if the model correctly predicted fire for *at least one* fire pixel\n",
    "        fire_pixels_correctly_predicted = np.sum(\n",
    "            (Y_true_batch.numpy() > 0) & (Y_pred_classes > 0)\n",
    "        )\n",
    "        \n",
    "        if fire_pixels_correctly_predicted > 0:\n",
    "            FIRE_PREDICTION_FOUND = True\n",
    "            \n",
    "            # Since we cannot access the original index from the generator efficiently, \n",
    "            # we report the sample counter as a demonstration index.\n",
    "            \n",
    "            print(\"\\n✅ **SUCCESS! TRUE POSITIVE SAMPLE FOUND.**\")\n",
    "            print(f\"Local Sample Index in Validation Dataset: {sample_counter}\")\n",
    "            print(f\"Total True Fire Pixels in Sample: {np.sum(Y_true_batch.numpy() > 0)}\")\n",
    "            print(f\"Correctly Predicted Fire Pixels (TP): {fire_pixels_correctly_predicted}\")\n",
    "            \n",
    "            \n",
    "            # --- Date/Time Output ---\n",
    "            # To get the real date, you must map this sample_counter back to the original index in val_df.\n",
    "            if 'val_df' in locals():\n",
    "                try:\n",
    "                    # The index in val_df corresponding to this sample (approximation)\n",
    "                    # NOTE: This is an approximation since generator shuffling complicates index mapping.\n",
    "                    approx_df_index = val_df.index[sample_counter]\n",
    "                    \n",
    "                    # Assuming df (full original dataframe) is also available and indexed by the original csv rows.\n",
    "                    full_df_index = df.index[approx_df_index] # Get the original index from the full df\n",
    "                    \n",
    "                    start_time, end_time = get_sample_date_range(full_df_index, df)\n",
    "                    print(f\"\\n--- Prediction Window (APPROXIMATION) ---\")\n",
    "                    print(f\"Input Sequence Start: {start_time}\")\n",
    "                    print(f\"Prediction Horizon End: {end_time}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not map to date range. Error: {e}\")\n",
    "                    \n",
    "            # Stop after finding the first one\n",
    "            break\n",
    "            \n",
    "    sample_counter += 1\n",
    "\n",
    "if not FIRE_PREDICTION_FOUND:\n",
    "    print(\"\\n❌ No True Positive fire predictions found in the first pass of the validation dataset.\")\n",
    "    print(\"Your model may be biased towards predicting 'No Fire' even for high-AUC samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180c0a7a-c98a-478d-be57-2d63bac8a93e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
