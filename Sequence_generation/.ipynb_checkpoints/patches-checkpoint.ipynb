{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "058e0175-ef36-46b5-b2b1-1d35d258311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# =====================\n",
    "# CONFIG\n",
    "# =====================\n",
    "SEQ_LEN = 6                 # number of past timesteps to use\n",
    "HORIZONS = 3                # number of future timesteps to predict\n",
    "PATCH_SIZE = 13             # spatial patch size\n",
    "HALF = PATCH_SIZE // 2\n",
    "FILL_NAN_VALUE = 0.0\n",
    "\n",
    "REQUIRED_COLS = [\n",
    "    \"era5_t2m_file\", \"era5_d2m_file\", \"era5_tp_file\",\n",
    "    \"era5_u10_file\", \"era5_v10_file\",\n",
    "    \"viirs_file\", \"dem_file\", \"lulc_file\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ae142a5-292c-4193-9e60-d501771b46db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_single_raster(path):\n",
    "    \"\"\"Helper to load one raster efficiently (single band).\"\"\"\n",
    "    try:\n",
    "        with rasterio.open(path, sharing=True) as src:\n",
    "            arr = src.read(1, out_dtype=\"float32\", masked=True)  # read first band\n",
    "            if np.ma.is_masked(arr):\n",
    "                arr = arr.filled(np.nan)\n",
    "            arr = np.nan_to_num(arr, nan=FILL_NAN_VALUE).astype(\"float32\", copy=False)\n",
    "            return arr\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d95c89-2d72-4f83-897d-966405060ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rasters(df, raster_cols, max_workers=8):\n",
    "    \"\"\"Load unique rasters into memory, cached, with multithreading.\"\"\"\n",
    "    all_paths = set()\n",
    "    for col in raster_cols:\n",
    "        if col in df.columns:\n",
    "            all_paths.update(df[col].dropna().unique())\n",
    "    all_paths = list(all_paths)\n",
    "\n",
    "    cache = {}\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        results = list(ex.map(_load_single_raster, all_paths))\n",
    "\n",
    "    for path, arr in zip(all_paths, results):\n",
    "        if arr is not None:\n",
    "            cache[path] = arr\n",
    "    return cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f852d13a-0952-4b2c-b861-3443a07960e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_norm_stats(arrays):\n",
    "    \"\"\"Compute mean & std for normalization.\"\"\"\n",
    "    valid = np.concatenate([a[~np.isnan(a)].ravel() for a in arrays])\n",
    "    mean, std = valid.mean(), valid.std()\n",
    "    return mean, std\n",
    "\n",
    "def normalize(arr, mean, std):\n",
    "    return (arr - mean) / std\n",
    "\n",
    "def encode_lulc(lulc_arr, known_classes=None):\n",
    "    \"\"\"One-hot encode LULC raster.\"\"\"\n",
    "    flat = lulc_arr.ravel().astype(int).reshape(-1, 1)\n",
    "\n",
    "    enc = OneHotEncoder(categories=[known_classes] if known_classes else \"auto\", sparse=False)\n",
    "    onehot = enc.fit_transform(flat)\n",
    "\n",
    "    onehot_img = onehot.reshape(lulc_arr.shape[0], lulc_arr.shape[1], -1)\n",
    "    return onehot_img, enc.categories_[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edee5feb-0f88-4090-ab3f-4c28838c8f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_center(h, w, patch_size=PATCH_SIZE):\n",
    "    half = patch_size // 2\n",
    "    r = np.clip(h // 2, half, h - half - 1)\n",
    "    c = np.clip(w // 2, half, w - half - 1)\n",
    "    return r, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fce6a62-85f9-4b91-a739-a40022b4718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_patch(arr, row, col, patch_size=PATCH_SIZE):\n",
    "    half = patch_size // 2\n",
    "    return arr[row-half:row+half+1, col-half:col+half+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e402e30a-b656-4fe1-9eb9-99fc3e3171a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sample(seq_rows, horizon_rows, cache):\n",
    "    \"\"\"\n",
    "    Build one training sample:\n",
    "      seq_rows: past SEQ_LEN rows from CSV\n",
    "      horizon_rows: next HORIZONS rows from CSV\n",
    "    Returns:\n",
    "      X: (SEQ_LEN, PATCH_SIZE, PATCH_SIZE, 7)\n",
    "      y: (HORIZONS, PATCH_SIZE, PATCH_SIZE)\n",
    "    \"\"\"\n",
    "    seq_patches = []\n",
    "    # --- sequence input ---\n",
    "    for _, row in seq_rows.iterrows():\n",
    "        bands = []\n",
    "        for var in [\"era5_t2m_file\", \"era5_d2m_file\", \"era5_tp_file\", \"era5_u10_file\", \"era5_v10_file\"]:\n",
    "            arr = cache[row[var]]\n",
    "            r, c = _safe_center(*arr.shape)\n",
    "            bands.append(_extract_patch(arr, r, c))\n",
    "        # static vars\n",
    "        dem = cache[row[\"dem_file\"]]\n",
    "        lulc = cache[row[\"lulc_file\"]]\n",
    "        r, c = _safe_center(*dem.shape)\n",
    "        dem_patch = _extract_patch(dem, r, c)\n",
    "        lulc_patch = _extract_patch(lulc, r, c)\n",
    "        bands.append(dem_patch)\n",
    "        bands.append(lulc_patch)\n",
    "\n",
    "        stack = np.stack(bands, axis=-1)  # (P, P, 7)\n",
    "        seq_patches.append(stack)\n",
    "\n",
    "    X = np.stack(seq_patches, axis=0)  # (SEQ_LEN, P, P, 7)\n",
    "\n",
    "    # --- horizon target ---\n",
    "    horizon_patches = []\n",
    "    for _, row in horizon_rows.iterrows():\n",
    "        arr = cache[row[\"viirs_file\"]]\n",
    "        r, c = _safe_center(*arr.shape)\n",
    "        horizon_patches.append(_extract_patch(arr, r, c))\n",
    "    y = np.stack(horizon_patches, axis=0)  # (HORIZONS, P, P)\n",
    "\n",
    "    return X.astype(\"float32\"), y.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afdf22cf-fdf9-4d61-920d-8afba9b072c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(csv_path, cache):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    missing = [c for c in REQUIRED_COLS if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"CSV missing required columns: {missing}\")\n",
    "\n",
    "    for i in range(len(df) - SEQ_LEN - HORIZONS + 1):\n",
    "        seq_rows = df.iloc[i : i + SEQ_LEN]\n",
    "        horizon_rows = df.iloc[i + SEQ_LEN : i + SEQ_LEN + HORIZONS]\n",
    "        yield build_sample(seq_rows, horizon_rows, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbccc812-c0bf-4446-9bbe-8e352a0c2ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(csv_path, cache, batch_size=4, shuffle=True, shuffle_buf=256):\n",
    "    output_signature = (\n",
    "        tf.TensorSpec(shape=(SEQ_LEN, PATCH_SIZE, PATCH_SIZE, 7), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(HORIZONS, PATCH_SIZE, PATCH_SIZE), dtype=tf.float32),\n",
    "    )\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        lambda: make_generator(csv_path, cache),\n",
    "        output_signature=output_signature\n",
    "    )\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_buf, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e327f91e-e454-4b6c-8ea4-f6b8b6aae545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading rasters into memory...\n",
      "Loaded 9 rasters into memory ✅\n",
      "X shape: (2, 6, 13, 13, 7)\n",
      "y shape: (2, 3, 13, 13)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    csv_path = r\"C:\\Users\\Ankit\\Datasets_Forest_fire\\sequence_index_hourly_norm.csv\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    raster_cols = REQUIRED_COLS\n",
    "    print(\"Loading rasters into memory...\")\n",
    "    cache = load_rasters(df, raster_cols, max_workers=8)\n",
    "    print(f\"Loaded {len(cache)} rasters into memory ✅\")\n",
    "\n",
    "    ds = create_dataset(csv_path, cache, batch_size=2)\n",
    "    for X, y in ds.take(1):\n",
    "        print(\"X shape:\", X.shape)  # (B, SEQ_LEN, PATCH, PATCH, 7)\n",
    "        print(\"y shape:\", y.shape)  # (B, HORIZONS, PATCH, PATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2982971f-a41a-4220-b7f0-afc46bf0b4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "for X, y in ds.take(1):\n",
    "    print(type(X), type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf08e23-1fb9-4974-8c8c-9e8f7aa7e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import random\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7865da8-3220-49fa-8d23-16564f980994",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN     = 6\n",
    "HORIZONS    = [1, 2, 3]\n",
    "PATCH_SIZE  = 13  \n",
    "BATCH_SIZE  = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73a23609-a2ce-4f9f-8846-46de9eff05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_CSV = r\"C:\\Users\\Ankit\\Datasets_Forest_fire\\sequence_index_hourly_norm.csv\"\n",
    "df = pd.read_csv(SEQ_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d011b055-9544-4b41-96b7-11b2fa396e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as in the read_csv , it was stored as string \"[1,,2,3,4,5,6]\", so through ast.literal_eval we convert it into python list\n",
    "df[\"seq_band_idxs\"] = df[\"seq_band_idxs\"].apply(ast.literal_eval)\n",
    "df[\"target_band_idxs\"] = df[\"target_band_idxs\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42f826a1-ed62-4a49-93a8-7bf2cda29b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_patch(file, band_idx, row, col, size=PATCH_SIZE):\n",
    "    with rasterio.open(file) as src:\n",
    "        # Window (row, col) is center pixel\n",
    "        row_off = max(row - size // 2, 0)\n",
    "        col_off = max(col - size // 2, 0)\n",
    "        window = rasterio.windows.Window(col_off, row_off, size, size)\n",
    "        arr = src.read(band_idx+1, window=window)  # rasterio bands are 1-based\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "453cb015-54d7-4bb4-ad97-908ff60ef5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_generator():\n",
    "    while True:\n",
    "        # Randomly pick a row from index\n",
    "        row = df.sample(1).iloc[0]\n",
    "\n",
    "        # Random pixel location\n",
    "        with rasterio.open(row[\"era5_t2m_file\"]) as src:\n",
    "            h, w = src.height, src.width\n",
    "        r = random.randint(PATCH_SIZE//2, h - PATCH_SIZE//2 - 1)\n",
    "        c = random.randint(PATCH_SIZE//2, w - PATCH_SIZE//2 - 1)\n",
    "\n",
    "        # ---- Input sequence ----\n",
    "        seq_bands = row[\"seq_band_idxs\"]\n",
    "        x_vars = []\n",
    "        for f in [\"era5_t2m_file\", \"era5_d2m_file\", \"era5_tp_file\", \n",
    "                  \"era5_u10_file\", \"era5_v10_file\"]:\n",
    "            var_stack = []\n",
    "            for b in seq_bands:\n",
    "                patch = read_patch(row[f], b, r, c)\n",
    "                var_stack.append(patch)\n",
    "            x_vars.append(np.stack(var_stack, axis=0))  # (time, H, W)\n",
    "\n",
    "        # DEM (static)\n",
    "        dem_patch = read_patch(row[\"dem_file\"], 0, r, c)\n",
    "        x_vars.append(np.repeat(dem_patch[None, :, :], SEQ_LEN, axis=0))\n",
    "\n",
    "        # LULC (static categorical, already one-hot TIFF)\n",
    "        lulc_patch = read_patch(row[\"lulc_file\"], 0, r, c)\n",
    "        x_vars.append(np.repeat(lulc_patch[None, :, :], SEQ_LEN, axis=0))\n",
    "\n",
    "        x = np.stack(x_vars, axis=-1)  # shape: (time, H, W, channels)\n",
    "\n",
    "        # ---- Targets ----\n",
    "        tgt_bands = row[\"target_band_idxs\"]\n",
    "        y_vars = []\n",
    "        for b in tgt_bands:\n",
    "            patch = read_patch(row[\"viirs_file\"], b, r, c)\n",
    "            y_vars.append(patch)\n",
    "        y = np.stack(y_vars, axis=0)  # shape: (horizons, H, W)\n",
    "\n",
    "        yield x.astype(np.float32), y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "add028ed-eec0-4ab8-b875-d11903e0fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_signature = (\n",
    "    tf.TensorSpec(shape=(SEQ_LEN, PATCH_SIZE, PATCH_SIZE, None), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(len(HORIZONS), PATCH_SIZE, PATCH_SIZE), dtype=tf.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee0dd7b8-56df-4e6f-8bcf-67118893addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(sample_generator, output_signature=output_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ac89a0d-5967-4c2e-8eaf-a59d16298b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL = 1000  \n",
    "VAL_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4546dee1-3d53-46d5-9106-46661e48cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(1000, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db6cab87-37a9-4cb3-9476-6224a906a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = int(TOTAL * VAL_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39a3c9ef-b7c9-4974-828d-2e8107cf4bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = dataset.take(val_size)\n",
    "train_dataset = dataset.skip(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7235e2b-7189-4cbb-9701-9bbaeebd0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset   = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90893721-b56d-4630-b86d-cf7a92ef7fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e700a567-9a37-440c-9e04-d691f0824fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 6           \n",
    "PATCH_H = 13            \n",
    "PATCH_W = 13          \n",
    "CHANNELS = 7       \n",
    "HORIZONS = 3            \n",
    "LSTM_UNITS = 16      \n",
    "CNN_FEATURES = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27354090-4f0c-46e7-a8d1-0d0897ea2f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_lstm_model(seq_len=SEQ_LEN, patch_h=PATCH_H, patch_w=PATCH_W, channels=CHANNELS, horizons=HORIZONS):\n",
    "\n",
    "    inp = layers.Input(shape=(seq_len, patch_h, patch_w, channels))\n",
    "\n",
    "    def build_cnn_block():\n",
    "        model = models.Sequential([\n",
    "            layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2,2)),\n",
    "            layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2,2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(CNN_FEATURES, activation='relu')\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    cnn = build_cnn_block()\n",
    "    td = layers.TimeDistributed(cnn)(inp) \n",
    "    \n",
    "    lstm_out = layers.LSTM(LSTM_UNITS)(td)\n",
    "\n",
    "    #for spatial features as an output\n",
    "    reg_out = layers.Dense(horizons * patch_h * patch_w, activation=\"linear\")(lstm_out)\n",
    "    reg_out = layers.Reshape((horizons, patch_h, patch_w),name=\"reg_out\")(reg_out)\n",
    "\n",
    "    #fire/no fire\n",
    "    cls_out = layers.Dense(1, activation=\"sigmoid\",name=\"cls_out\")(lstm_out)  \n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=[reg_out, cls_out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0edd5396-3de9-4d23-9be3-633aa055e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Derive a binary fire/no-fire label from y_reg (any fire anywhere in any horizon)\n",
    "FIRE_THRESHOLD = 0.5  # adjust if your VIIRS is 0/1 keep at 0.5\n",
    "\n",
    "def add_cls_label_batched(X, y_reg):\n",
    "    # y_reg: (B, HORIZONS, H, W)\n",
    "    # take max over horizons+pixels -> (B,)\n",
    "    y_cls = tf.reduce_max(y_reg, axis=[1, 2, 3])\n",
    "    y_cls = tf.cast(y_cls > FIRE_THRESHOLD, tf.float32)  # (B,)\n",
    "    y_cls = tf.expand_dims(y_cls, axis=-1)               # (B, 1)\n",
    "    return X, {\"reg_out\": y_reg, \"cls_out\": y_cls}\n",
    "\n",
    "train_dataset = train_dataset.map(add_cls_label_batched, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset   = val_dataset.map(add_cls_label_batched,   num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1facc312-f129-4295-b1e7-ad3a46ed0a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_cnn_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b34b9c2e-8951-40d3-87ef-f9ad475ca540",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "234ff4d1-7ba6-4ded-b755-ac49b2680b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ time_distributed              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">57,472</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)             │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,184</span> │ time_distributed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">507</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,619</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ reg_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cls_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                 │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m7\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ time_distributed              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m57,472\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)             │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │           \u001b[38;5;34m5,184\u001b[0m │ time_distributed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m507\u001b[0m)               │           \u001b[38;5;34m8,619\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ reg_out (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cls_out (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m17\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                 │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,292</span> (278.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m71,292\u001b[0m (278.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,292</span> (278.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m71,292\u001b[0m (278.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e92766c1-8599-4ad5-8b12-7b77371b345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd2f64e9-74fb-4b7c-9ffc-de3555b0238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_cnn_lstm_model(\n",
    "    seq_len=SEQ_LEN,\n",
    "    patch_h=PATCH_H,\n",
    "    patch_w=PATCH_W,\n",
    "    channels=CHANNELS,\n",
    "    horizons=HORIZONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "040d3ca1-db4a-4d5d-ae17-2848bcbeaa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss={\n",
    "        \"reg_out\": tf.keras.losses.MeanSquaredError(),\n",
    "        \"cls_out\": tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    },\n",
    "    loss_weights={\"reg_out\": 1.0, \"cls_out\": 0.3},\n",
    "    metrics={\"reg_out\": [tf.keras.metrics.MeanAbsoluteError()],\n",
    "             \"cls_out\": [tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.AUC()]},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f87cb8a8-b977-489f-a3cd-e8e4d93cad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,            # stop if val_loss doesn't improve for 5 epochs\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    \"best_cnn_lstm_model.h5\",\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aacb94-0770-44f8-bd4f-ea2f79b1cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=1,\n",
    "    callbacks=[early_stop, checkpoint], \n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9064d8de-8857-4b78-a16a-af8e6b989f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
