{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17b97c66-082d-4a6e-93a8-fdab3c13be54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "\n",
    "# =====================\n",
    "# CONFIG\n",
    "# =====================\n",
    "SEQ_LEN = 6                # past 6 timesteps\n",
    "HORIZONS = 3               # predict next 3 hours\n",
    "PATCH_SIZE = 13           # patch size\n",
    "HALF = PATCH_SIZE // 2\n",
    "\n",
    "# CSV must have at least these columns\n",
    "required = [\"seq_band_idxs\", \"target_band_idxs\",\n",
    "            \"era5_t2m_file\", \"era5_d2m_file\", \"era5_tp_file\",\n",
    "            \"era5_u10_file\", \"era5_v10_file\",\n",
    "            \"viirs_file\", \"dem_file\", \"lulc_file\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7ec60d3-3805-40c0-bebd-492a8d8bc4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankit\\Datasets_Forest_fire\\ERA5_fast_tif_stacks\\ERA5_t2m_2015_2016_stack.tif → (17, 13)\n",
      "C:\\Users\\Ankit\\Datasets_Forest_fire\\ERA5_fast_tif_stacks\\ERA5_d2m_2015_2016_stack.tif → (17, 13)\n",
      "C:\\Users\\Ankit\\Datasets_Forest_fire\\ERA5_fast_tif_stacks\\ERA5_tp_2015_2016_stack.tif → (17, 13)\n",
      "C:\\Users\\Ankit\\Datasets_Forest_fire\\ERA5_fast_tif_stacks\\ERA5_u10_2015_2016_stack.tif → (17, 13)\n",
      "C:\\Users\\Ankit\\Datasets_Forest_fire\\ERA5_fast_tif_stacks\\ERA5_v10_2015_2016_stack.tif → (17, 13)\n",
      "C:\\Users\\Ankit\\Datasets_Forest_fire\\VIIRS_fire_time_stack.tif → (17, 13)\n",
      "C:\\Users\\Ankit\\Datasets_Forest_fire\\merged_DEM_30m_32644_aligned_filled.tif → (13604, 11904)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import rasterio\n",
    "\n",
    "# Path to your CSV\n",
    "csv_path = r\"C:\\Users\\Ankit\\Datasets_Forest_fire\\sequence_index_hourly.csv\"\n",
    "\n",
    "# Columns that contain raster file paths\n",
    "raster_cols = [\n",
    "    \"era5_t2m_file\", \"era5_d2m_file\", \"era5_tp_file\",\n",
    "    \"era5_u10_file\", \"era5_v10_file\",\n",
    "    \"viirs_file\", \"dem_file\", \"lulc2015_file\", \"lulc2016_file\"\n",
    "]\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Collect raster sizes\n",
    "sizes = {}\n",
    "\n",
    "for col in raster_cols:\n",
    "    if col not in df.columns:\n",
    "        continue\n",
    "    for path in df[col].dropna().unique():\n",
    "        try:\n",
    "            with rasterio.open(path) as src:\n",
    "                sizes[path] = (src.width, src.height)\n",
    "        except Exception as e:\n",
    "            sizes[path] = f\"Error: {e}\"\n",
    "\n",
    "# Show results\n",
    "for path, size in sizes.items():\n",
    "    print(f\"{path} → {size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f347aab9-6020-4b97-9b1c-997b10aaa55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_safe_center(h, w, patch_size=PATCH_SIZE):\n",
    "    half = patch_size // 2\n",
    "    r = h // 2\n",
    "    c = w // 2\n",
    "    r = np.clip(r, half, h - half - 1)\n",
    "    c = np.clip(c, half, w - half - 1)\n",
    "    return r, c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c77676b-992c-4482-b8de-8e0ce71c4a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patch(raster_path, r, c, patch_size=PATCH_SIZE):\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        H, W = src.height, src.width\n",
    "        if H < patch_size or W < patch_size:\n",
    "            raise ValueError(f\"Raster {raster_path} smaller than patch size.\")\n",
    "        window = rasterio.windows.Window(c - patch_size//2, r - patch_size//2,\n",
    "                                         patch_size, patch_size)\n",
    "        patch = src.read(1, window=window).astype(np.float32)\n",
    "        nodata = src.nodata\n",
    "        if nodata is not None:\n",
    "            patch = np.where(patch == nodata, np.nan, patch)\n",
    "    return patch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ee14c06-4d06-46da-85fa-67e6ffad2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sample(row, seq_len=SEQ_LEN, horizons=HORIZONS, patch_size=PATCH_SIZE):\n",
    "    # Open one raster to get safe center\n",
    "    with rasterio.open(row[\"era5_t2m_file\"]) as src:\n",
    "        H, W = src.height, src.width\n",
    "    r, c = get_safe_center(H, W, patch_size)\n",
    "\n",
    "    # Sequence ERA5 (5 vars × seq_len)\n",
    "    seq_patches = []\n",
    "    for fcol in [\"era5_t2m_file\", \"era5_d2m_file\", \"era5_tp_file\",\n",
    "                 \"era5_u10_file\", \"era5_v10_file\"]:\n",
    "        patch = extract_patch(row[fcol], r, c, patch_size)\n",
    "        seq_patches.append(patch)\n",
    "    seq_stack = np.stack(seq_patches, axis=-1)  # (H, W, 5)\n",
    "\n",
    "    # Static DEM\n",
    "    dem_patch = extract_patch(row[\"dem_file\"], r, c, patch_size)[..., None]\n",
    "\n",
    "    # Static LULC (only one file now)\n",
    "    lulc_patch = extract_patch(row[\"lulc_file\"], r, c, patch_size)[..., None]\n",
    "\n",
    "    # Combine static → (H, W, 2)\n",
    "    static_stack = np.concatenate([dem_patch, lulc_patch], axis=-1)\n",
    "\n",
    "    # Expand static to each timestep → (seq_len, H, W, 2)\n",
    "    static_seq = np.repeat(static_stack[None, ...], seq_len, axis=0)\n",
    "\n",
    "    # Expand ERA5 to match sequence → (seq_len, H, W, 5)\n",
    "    seq_seq = np.repeat(seq_stack[None, ...], seq_len, axis=0)\n",
    "\n",
    "    # Final input X = (seq_len, H, W, channels=7)\n",
    "    X = np.concatenate([seq_seq, static_seq], axis=-1)\n",
    "\n",
    "    # Target VIIRS (3 horizons)\n",
    "    target_patch = extract_patch(row[\"viirs_file\"], r, c, patch_size)\n",
    "    y = np.repeat(target_patch[None, ...], horizons, axis=0)  # (HORIZONS, H, W)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff8efb2d-fe35-4d1b-a1e4-67bae49efea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # Check required columns\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"CSV missing columns: {missing}\")\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        yield extract_sample(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0113892f-10cd-4e1e-ac4b-2eb50b94cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(csv_path, batch_size=4, shuffle=True):\n",
    "    output_signature = (\n",
    "        tf.TensorSpec(shape=(SEQ_LEN, PATCH_SIZE, PATCH_SIZE, 7), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(HORIZONS, PATCH_SIZE, PATCH_SIZE), dtype=tf.float32),\n",
    "    )\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        lambda: generator(csv_path),\n",
    "        output_signature=output_signature\n",
    "    )\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(100)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e89f78c-e8f8-4824-b138-960e2f8e7826",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    csv_path = r\"C:\\Users\\Ankit\\Datasets_Forest_fire\\sequence_index_hourly.csv\"   # <-- put your CSV here\n",
    "    ds = create_dataset(csv_path, batch_size=2)\n",
    "    for X, y in ds.take(1):\n",
    "        print(\"X shape:\", X.shape)  # (B, SEQ_LEN, PATCH, PATCH, 8)\n",
    "        print(\"y shape:\", y.shape)  # (B, HORIZONS, PATCH, PATCH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03432798-7782-4e50-b401-34bfb646edf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
