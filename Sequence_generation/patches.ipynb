{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "058e0175-ef36-46b5-b2b1-1d35d258311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "SEQ_LEN = 6                 \n",
    "HORIZONS = 3               \n",
    "PATCH_SIZE = 13             \n",
    "HALF = PATCH_SIZE // 2\n",
    "FILL_NAN_VALUE = 0.0\n",
    "\n",
    "REQUIRED_COLS = [\n",
    "    \"era5_t2m_file\", \"era5_d2m_file\", \"era5_tp_file\",\n",
    "    \"era5_u10_file\", \"era5_v10_file\",\n",
    "    \"viirs_file\", \"dem_file\", \"lulc_file\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ae142a5-292c-4193-9e60-d501771b46db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_single_raster(path):\n",
    "    \"\"\"Helper to load one raster efficiently (single band).\"\"\"\n",
    "    try:\n",
    "        with rasterio.open(path, sharing=True) as src:\n",
    "            arr = src.read(1, out_dtype=\"float32\", masked=True)  # read first band\n",
    "\n",
    "            #masked=True → treat NoData values as a masked array (special numpy array where invalid values are marked)\n",
    "            \n",
    "            if np.ma.is_masked(arr):\n",
    "                arr = arr.filled(np.nan)\n",
    "            arr = np.nan_to_num(arr, nan=FILL_NAN_VALUE).astype(\"float32\", copy=False)\n",
    "            return arr\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38d95c89-2d72-4f83-897d-966405060ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rasters(df, raster_cols, max_workers=8):\n",
    "    \"\"\"Load unique rasters into memory, cached, with multithreading.\"\"\"\n",
    "    all_paths = set() #setting to zero , means no path yet\n",
    "    \n",
    "    for col in raster_cols:\n",
    "        if col in df.columns:\n",
    "            all_paths.update(df[col].dropna().unique())\n",
    "    all_paths = list(all_paths) #in this we added, the raster paths and also jha pe bhi nan h ,we delete those datas\n",
    "\n",
    "    cache = {}\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        results = list(ex.map(_load_single_raster, all_paths))\n",
    "\n",
    "    for path, arr in zip(all_paths, results):\n",
    "        if arr is not None:\n",
    "            cache[path] = arr\n",
    "    return cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f852d13a-0952-4b2c-b861-3443a07960e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_norm_stats(arrays):\n",
    "    \"\"\"Compute mean & std for normalization.\"\"\"\n",
    "    valid = np.concatenate([a[~np.isnan(a)].ravel() for a in arrays])\n",
    "    mean, std = valid.mean(), valid.std()\n",
    "    return mean, std\n",
    "\n",
    "def normalize(arr, mean, std):\n",
    "    return (arr - mean) / std\n",
    "\n",
    "def encode_lulc(lulc_arr, known_classes=None):\n",
    "    \"\"\"One-hot encode LULC raster.\"\"\"\n",
    "    flat = lulc_arr.ravel().astype(int).reshape(-1, 1)\n",
    "\n",
    "    enc = OneHotEncoder(categories=[known_classes] if known_classes else \"auto\", sparse=False)\n",
    "    onehot = enc.fit_transform(flat)\n",
    "\n",
    "    onehot_img = onehot.reshape(lulc_arr.shape[0], lulc_arr.shape[1], -1)\n",
    "    return onehot_img, enc.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edee5feb-0f88-4090-ab3f-4c28838c8f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_center(h, w, patch_size=PATCH_SIZE):\n",
    "    half = patch_size // 2\n",
    "    r = np.clip(h // 2, half, h - half - 1)\n",
    "    c = np.clip(w // 2, half, w - half - 1)\n",
    "    return r, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fce6a62-85f9-4b91-a739-a40022b4718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_patch(arr, row, col, patch_size=PATCH_SIZE):\n",
    "    half = patch_size // 2\n",
    "    return arr[row-half:row+half+1, col-half:col+half+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e402e30a-b656-4fe1-9eb9-99fc3e3171a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sample(seq_rows, horizon_rows, cache):\n",
    "\n",
    "    seq_patches = []\n",
    "\n",
    "    for _, row in seq_rows.iterrows():\n",
    "        bands = []\n",
    "        for var in [\"era5_t2m_file\", \"era5_d2m_file\", \"era5_tp_file\", \"era5_u10_file\", \"era5_v10_file\"]:\n",
    "            arr = cache[row[var]]\n",
    "            r, c = _safe_center(*arr.shape)\n",
    "            bands.append(_extract_patch(arr, r, c))\n",
    "            \n",
    "        # static vars\n",
    "        dem = cache[row[\"dem_file\"]]\n",
    "        lulc = cache[row[\"lulc_file\"]]\n",
    "        r, c = _safe_center(*dem.shape)\n",
    "        dem_patch = _extract_patch(dem, r, c)\n",
    "        lulc_patch = _extract_patch(lulc, r, c)\n",
    "        bands.append(dem_patch)\n",
    "        bands.append(lulc_patch)\n",
    "\n",
    "        stack = np.stack(bands, axis=-1)  \n",
    "        seq_patches.append(stack)\n",
    "\n",
    "    X = np.stack(seq_patches, axis=0)  \n",
    "\n",
    "\n",
    "    horizon_patches = []\n",
    "    for _, row in horizon_rows.iterrows():\n",
    "        arr = cache[row[\"viirs_file\"]]\n",
    "        r, c = _safe_center(*arr.shape)\n",
    "        horizon_patches.append(_extract_patch(arr, r, c))\n",
    "    y = np.stack(horizon_patches, axis=0)  \n",
    "\n",
    "    return X.astype(\"float32\"), y.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afdf22cf-fdf9-4d61-920d-8afba9b072c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(csv_path, cache):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    missing = [c for c in REQUIRED_COLS if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"CSV missing required columns: {missing}\")\n",
    "\n",
    "    for i in range(len(df) - SEQ_LEN - HORIZONS + 1):\n",
    "        seq_rows = df.iloc[i : i + SEQ_LEN]\n",
    "        horizon_rows = df.iloc[i + SEQ_LEN : i + SEQ_LEN + HORIZONS]\n",
    "        yield build_sample(seq_rows, horizon_rows, cache)\n",
    "\n",
    "#the reason of choosing yeild over return is to , get sample one by one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbccc812-c0bf-4446-9bbe-8e352a0c2ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(csv_path, cache, batch_size=4, shuffle=True, shuffle_buf=256):\n",
    "    #output_signature :- defines how training sample will look like\n",
    "    \n",
    "    output_signature = (\n",
    "        tf.TensorSpec(shape=(SEQ_LEN, PATCH_SIZE, PATCH_SIZE, 7), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(HORIZONS, PATCH_SIZE, PATCH_SIZE), dtype=tf.float32),\n",
    "    )\n",
    "    \n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        lambda: make_generator(csv_path, cache),\n",
    "        output_signature=output_signature\n",
    "    )\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_buf, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size) #creates the batch , while yeilding in make_generator() it will yeild  4batches at a time \n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE) #this loads the next sample of the batch\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e327f91e-e454-4b6c-8ea4-f6b8b6aae545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading rasters into memory...\n",
      "Loaded 9 rasters into memory ✅\n",
      "X shape: (2, 6, 13, 13, 7)\n",
      "y shape: (2, 3, 13, 13)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    csv_path = r\"C:\\Users\\Ankit\\Datasets_Forest_fire\\sequence_index_hourly_norm.csv\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    raster_cols = REQUIRED_COLS\n",
    "    print(\"Loading rasters into memory...\")\n",
    "    cache = load_rasters(df, raster_cols, max_workers=8)\n",
    "    print(f\"Loaded {len(cache)} rasters into memory ✅\")\n",
    "\n",
    "    ds = create_dataset(csv_path, cache, batch_size=2)\n",
    "    for X, y in ds.take(1):\n",
    "        print(\"X shape:\", X.shape)  # (B, SEQ_LEN, PATCH, PATCH, 7)\n",
    "        print(\"y shape:\", y.shape)  # (B, HORIZONS, PATCH, PATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2982971f-a41a-4220-b7f0-afc46bf0b4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "for X, y in ds.take(1):\n",
    "    print(type(X), type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "103af332-026d-4a6f-9d6f-a11f17ef551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL = 1000  \n",
    "VAL_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fce5a3e5-f7df-482e-851e-64a983e631e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.shuffle(1000, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b1f3d67-7ef7-465c-a2a8-321ff13bfb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = int(TOTAL * VAL_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0be4f002-378a-4856-9040-4fe86aa5b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = ds.take(val_size)\n",
    "train_dataset = ds.skip(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3711b3f8-bdc6-41a5-9bab-91e406ada3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=4\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset   = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c5c5c-a039-4939-b316-c9b3e4db71f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e50094-9674-4b1a-b6f7-070789533b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dea7aedd-d443-48ef-baa5-a60b6d741495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd approach for the same dataset pipelining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf08e23-1fb9-4974-8c8c-9e8f7aa7e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import random\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7865da8-3220-49fa-8d23-16564f980994",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN     = 6\n",
    "HORIZONS    = [1, 2, 3]\n",
    "PATCH_SIZE  = 13  \n",
    "BATCH_SIZE  = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73a23609-a2ce-4f9f-8846-46de9eff05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_CSV = r\"C:\\Users\\Ankit\\Datasets_Forest_fire\\sequence_index_hourly_norm.csv\"\n",
    "df = pd.read_csv(SEQ_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d011b055-9544-4b41-96b7-11b2fa396e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as in the read_csv , it was stored as string \"[1,,2,3,4,5,6]\", so through ast.literal_eval we convert it into python list\n",
    "df[\"seq_band_idxs\"] = df[\"seq_band_idxs\"].apply(ast.literal_eval)\n",
    "df[\"target_band_idxs\"] = df[\"target_band_idxs\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42f826a1-ed62-4a49-93a8-7bf2cda29b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_patch(file, band_idx, row, col, size=PATCH_SIZE):\n",
    "    with rasterio.open(file) as src:\n",
    "        # Window (row, col) is center pixel\n",
    "        row_off = max(row - size // 2, 0)\n",
    "        col_off = max(col - size // 2, 0)\n",
    "        window = rasterio.windows.Window(col_off, row_off, size, size)\n",
    "        arr = src.read(band_idx+1, window=window)  # rasterio bands are 1-based\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "453cb015-54d7-4bb4-ad97-908ff60ef5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_generator():\n",
    "    while True:\n",
    "        \n",
    "        row = df.sample(1).iloc[0]\n",
    "\n",
    "        \n",
    "        with rasterio.open(row[\"era5_t2m_file\"]) as src:\n",
    "            h, w = src.height, src.width\n",
    "        r = random.randint(PATCH_SIZE//2, h - PATCH_SIZE//2 - 1)\n",
    "        c = random.randint(PATCH_SIZE//2, w - PATCH_SIZE//2 - 1)\n",
    "\n",
    "        \n",
    "        seq_bands = row[\"seq_band_idxs\"]\n",
    "        x_vars = []\n",
    "        for f in [\"era5_t2m_file\", \"era5_d2m_file\", \"era5_tp_file\", \n",
    "                  \"era5_u10_file\", \"era5_v10_file\"]:\n",
    "            var_stack = []\n",
    "            for b in seq_bands:\n",
    "                patch = read_patch(row[f], b, r, c)\n",
    "                var_stack.append(patch)\n",
    "            x_vars.append(np.stack(var_stack, axis=0))  # (time, H, W)\n",
    "\n",
    "        \n",
    "        dem_patch = read_patch(row[\"dem_file\"], 0, r, c)\n",
    "        x_vars.append(np.repeat(dem_patch[None, :, :], SEQ_LEN, axis=0))\n",
    "\n",
    "        \n",
    "        lulc_patch = read_patch(row[\"lulc_file\"], 0, r, c)\n",
    "        x_vars.append(np.repeat(lulc_patch[None, :, :], SEQ_LEN, axis=0))\n",
    "\n",
    "        x = np.stack(x_vars, axis=-1)  # shape: (time, H, W, channels)\n",
    "\n",
    "        \n",
    "        tgt_bands = row[\"target_band_idxs\"]\n",
    "        y_vars = []\n",
    "        for b in tgt_bands:\n",
    "            patch = read_patch(row[\"viirs_file\"], b, r, c)\n",
    "            y_vars.append(patch)\n",
    "        y = np.stack(y_vars, axis=0)  \n",
    "\n",
    "        yield x.astype(np.float32), y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "add028ed-eec0-4ab8-b875-d11903e0fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_signature = (\n",
    "    tf.TensorSpec(shape=(SEQ_LEN, PATCH_SIZE, PATCH_SIZE, None), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(len(HORIZONS), PATCH_SIZE, PATCH_SIZE), dtype=tf.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee0dd7b8-56df-4e6f-8bcf-67118893addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(sample_generator, output_signature=output_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ac89a0d-5967-4c2e-8eaf-a59d16298b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL = 1000  \n",
    "VAL_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4546dee1-3d53-46d5-9106-46661e48cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(1000, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db6cab87-37a9-4cb3-9476-6224a906a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = int(TOTAL * VAL_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39a3c9ef-b7c9-4974-828d-2e8107cf4bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = dataset.take(val_size)\n",
    "train_dataset = dataset.skip(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7235e2b-7189-4cbb-9701-9bbaeebd0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset   = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd6271-29b2-4951-b20f-413cbaf2ccb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5fc03f-cd48-4ed7-bbca-f30245bc25ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90893721-b56d-4630-b86d-cf7a92ef7fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e700a567-9a37-440c-9e04-d691f0824fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 6           \n",
    "PATCH_H = 13            \n",
    "PATCH_W = 13          \n",
    "CHANNELS = 7       \n",
    "HORIZONS = 3            \n",
    "LSTM_UNITS = 16      \n",
    "CNN_FEATURES = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27354090-4f0c-46e7-a8d1-0d0897ea2f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_lstm_model(seq_len=SEQ_LEN, patch_h=PATCH_H, patch_w=PATCH_W, channels=CHANNELS, horizons=HORIZONS):\n",
    "\n",
    "    inp = layers.Input(shape=(seq_len, patch_h, patch_w, channels))\n",
    "\n",
    "    def build_cnn_block():\n",
    "        model = models.Sequential([\n",
    "            layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2,2)),\n",
    "            layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2,2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(CNN_FEATURES, activation='relu')\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    cnn = build_cnn_block()\n",
    "    td = layers.TimeDistributed(cnn)(inp) \n",
    "    \n",
    "    lstm_out = layers.LSTM(LSTM_UNITS)(td)\n",
    "\n",
    "    #for spatial features as an output\n",
    "    reg_out = layers.Dense(horizons * patch_h * patch_w, activation=\"linear\")(lstm_out)\n",
    "    reg_out = layers.Reshape((horizons, patch_h, patch_w),name=\"reg_out\")(reg_out)\n",
    "\n",
    "    #fire/no fire\n",
    "    cls_out = layers.Dense(1, activation=\"sigmoid\",name=\"cls_out\")(lstm_out)  \n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=[reg_out, cls_out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0edd5396-3de9-4d23-9be3-633aa055e861",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Ankit\\AppData\\Local\\Temp\\ipykernel_23844\\1103860906.py\", line 8, in add_cls_label_batched  *\n        y_cls = tf.reduce_max(y_reg, axis=[1, 2, 3])\n\n    TypeError: Expected any non-tensor type, but got a tensor instead.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     y_cls \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(y_cls, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)               \u001b[38;5;66;03m# (B, 1)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreg_out\u001b[39m\u001b[38;5;124m\"\u001b[39m: y_reg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls_out\u001b[39m\u001b[38;5;124m\"\u001b[39m: y_cls}\n\u001b[1;32m---> 13\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43madd_cls_label_batched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m val_dataset   \u001b[38;5;241m=\u001b[39m val_dataset\u001b[38;5;241m.\u001b[39mmap(add_cls_label_batched,   num_parallel_calls\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2341\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[0m\n\u001b[0;32m   2336\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[0;32m   2338\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   2339\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[1;32m-> 2341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2342\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2347\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_unbounded_threadpool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_unbounded_threadpool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2349\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:57\u001b[0m, in \u001b[0;36m_map_v2\u001b[1;34m(input_dataset, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synchronous:\n\u001b[0;32m     52\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     53\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`synchronous` is not supported with `num_parallel_calls`, but\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `num_parallel_calls` was set to \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m       num_parallel_calls,\n\u001b[0;32m     56\u001b[0m   )\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ParallelMapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_unbounded_threadpool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_unbounded_threadpool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:202\u001b[0m, in \u001b[0;36m_ParallelMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, use_unbounded_threadpool, name)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1256\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1255\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[1;32m-> 1256\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1257\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1258\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1226\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1224\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1225\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1226\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m   1230\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m   1231\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[0;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[0;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[0;32m    694\u001b[0m )\n\u001b[0;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[1;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[0;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[0;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[1;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[0;32m    290\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[1;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[0;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[0;32m    304\u001b[0m       placeholder_context\n\u001b[0;32m    305\u001b[0m   )\n\u001b[0;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    309\u001b[0m )\n\u001b[1;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[0;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1060\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[0;32m   1057\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m   1059\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1060\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    694\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileun1im721.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__add_cls_label_batched\u001b[1;34m(X, y_reg)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m y_cls \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_reg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m y_cls \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mld(y_cls) \u001b[38;5;241m>\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(FIRE_THRESHOLD), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mfloat32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m y_cls \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mexpand_dims, (ag__\u001b[38;5;241m.\u001b[39mld(y_cls),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), fscope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:472\u001b[0m, in \u001b[0;36m_AssertCompatible\u001b[1;34m(values, dtype)\u001b[0m\n\u001b[0;32m    470\u001b[0m [mismatch] \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39margs\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 472\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected any non-tensor type, but got a tensor instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    474\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmismatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    475\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(mismatch)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Ankit\\AppData\\Local\\Temp\\ipykernel_23844\\1103860906.py\", line 8, in add_cls_label_batched  *\n        y_cls = tf.reduce_max(y_reg, axis=[1, 2, 3])\n\n    TypeError: Expected any non-tensor type, but got a tensor instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "FIRE_THRESHOLD = 0.5  \n",
    "\n",
    "def add_cls_label_batched(X, y_reg):\n",
    "    # y_reg: (B, HORIZONS, H, W)\n",
    "    # take max over horizons+pixels -> (B,)\n",
    "    y_cls = tf.reduce_max(y_reg, axis=[1, 2, 3])\n",
    "    y_cls = tf.cast(y_cls > FIRE_THRESHOLD, tf.float32)  # (B,)\n",
    "    y_cls = tf.expand_dims(y_cls, axis=-1)               # (B, 1)\n",
    "    return X, {\"reg_out\": y_reg, \"cls_out\": y_cls}\n",
    "\n",
    "train_dataset = train_dataset.map(add_cls_label_batched, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset   = val_dataset.map(add_cls_label_batched,   num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1facc312-f129-4295-b1e7-ad3a46ed0a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_cnn_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b34b9c2e-8951-40d3-87ef-f9ad475ca540",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "234ff4d1-7ba6-4ded-b755-ac49b2680b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ time_distributed              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">57,472</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)             │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,184</span> │ time_distributed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">507</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,619</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ reg_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cls_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                 │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m7\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ time_distributed              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m57,472\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)             │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │           \u001b[38;5;34m5,184\u001b[0m │ time_distributed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m507\u001b[0m)               │           \u001b[38;5;34m8,619\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ reg_out (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ cls_out (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m17\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                 │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,292</span> (278.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m71,292\u001b[0m (278.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,292</span> (278.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m71,292\u001b[0m (278.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e92766c1-8599-4ad5-8b12-7b77371b345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd2f64e9-74fb-4b7c-9ffc-de3555b0238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_cnn_lstm_model(\n",
    "    seq_len=SEQ_LEN,\n",
    "    patch_h=PATCH_H,\n",
    "    patch_w=PATCH_W,\n",
    "    channels=CHANNELS,\n",
    "    horizons=HORIZONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "040d3ca1-db4a-4d5d-ae17-2848bcbeaa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss={\n",
    "        \"reg_out\": tf.keras.losses.MeanSquaredError(),\n",
    "        \"cls_out\": tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    },\n",
    "    loss_weights={\"reg_out\": 1.0, \"cls_out\": 0.3},\n",
    "    metrics={\"reg_out\": [tf.keras.metrics.MeanAbsoluteError()],\n",
    "             \"cls_out\": [tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.AUC()]},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f87cb8a8-b977-489f-a3cd-e8e4d93cad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,            # stop if val_loss doesn't improve for 5 epochs\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    \"best_cnn_lstm_model.h5\",\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aacb94-0770-44f8-bd4f-ea2f79b1cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=1,\n",
    "    callbacks=[early_stop, checkpoint], \n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9064d8de-8857-4b78-a16a-af8e6b989f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
